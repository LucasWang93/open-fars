Title: HybridINR-PCGC: Hybrid Lossless Point Cloud Geometry Compression Bridging Pretrained Model and Implicit Neural Representation

Abstract: Learning-based point cloud compression presents superior performance to handcrafted codecs. However, pretrained-based methods, which are based on end-to-end training and expected to generalize to all the potential samples, suffer from training data dependency. Implicit neural representation (INR) based methods are distribution-agnostic and more robust, but they require time-consuming online training and suffer from the bitstream overhead from the overfitted model. To address these limitations, we propose HybridINR-PCGC, a novel hybrid framework that bridges the pretrained model and INR. Our framework retains distribution-agnostic properties while leveraging a pretrained network to accelerate convergence and reduce model overhead, which consists of two parts: the Pretrained Prior Network (PPN) and the Distribution Agnostic Refiner (DAR). We leverage the PPN, designed for fast inference and stable performance, to generate a robust prior for accelerating the DAR's convergence. The DAR is decomposed into a base layer and an enhancement layer, and only the enhancement layer needed to be packed into the bitstream. Finally, we propose a supervised model compression module to further supervise and minimize the bitrate of the enhancement layer parameters. Based on experiment results, HybridINR-PCGC achieves a significantly improved compression rate and encoding efficiency. Specifically, our method achieves a Bpp reduction of approximately 20.43% compared to G-PCC on 8iVFB. In the challenging out-of-distribution scenario Cat1B, our method achieves a Bpp reduction of approximately 57.85% compared to UniPCGC. And our method exhibits a superior time-rate trade-off, achieving an average Bpp reduction of 15.193% relative to the LINR-PCGC on 8iVFB.

Body: HybridINR-PCGC: Hybrid Lossless Point Cloud Geometry Compression Bridging Pretrained Model and Implicit Neural Representation 1 Introduction 2 Related Work 2.1 Pretrained-based Methods 2.2 INR-based Methods 3 Preliminary 3.1 Group of Point Cloud (GoPC) 3.2 Octree Bottom-Up construction 4 Method 4.1 Pipeline 4.2 Pretrained Prior Network (PPN) 4.3 Distribution Agnostic Refiner (DAR) 4.4 Supervised Model Compression (SMC) 4.5 Loss Function 5 Experiment 5.1 Experiment Configuration 5.2 Experiment Result 5.3 Network Parameter Distribution Analysis 5.4 Bpp Allocation and Time Composition 5.5 Ablation Study 5.6 Conclusion 1 Appendix 1.1 Detail of parameters 1.2 Supplementary Experiment result 1.3 More Detail About PPN 1.4 Collaboration of PPN and DAR HybridINR-PCGC: Hybrid Lossless Point Cloud Geometry Compression Bridging Pretrained Model and Implicit Neural Representation Wenjie Huang 1 Qi Yang 2 Shuting Xia 1 He Huang 1 Zhu Li 2 Yiling Xu 1† 1 Shanghai Jiao Tong University 2 University of Missouri-Kansas City 1 {huangwenjie2023, xiashuting, huanghe0429, yl.xu}@sjtu.edu.cn , 2 {qiyang, lizhu}@umkc.edu Abstract Learning-based point cloud compression presents superior performance to handcrafted codecs. However, pretrained-based methods, which are based on end-to-end training and expected to generalize to all the potential samples, suffer from training data dependency. Implicit neural representation (INR) based methods are distribution-agnostic and more robust, but they require time-consuming online training and suffer from the bitstream overhead from the overfitted model. To address these limitations, we propose HybridINR-PCGC, a novel hybrid framework that bridges the pretrained model and INR. Our framework retains distribution-agnostic properties while leveraging a pretrained network to accelerate convergence and reduce model overhead, which consists of two parts: the Pretrained Prior Network (PPN) and the Distribution Agnostic Refiner (DAR). We leverage the PPN, designed for fast inference and stable performance, to generate a robust prior for accelerating the DAR’s convergence. The DAR is decomposed into a base layer and an enhancement layer, and only the enhancement layer needed to be packed into the bitstream. Finally, we propose a supervised model compression module to further supervise and minimize the bitrate of the enhancement layer parameters. Based on experiment results, HybridINR-PCGC achieves a significantly improved compression rate and encoding efficiency. Specifically, our method achieves a Bpp reduction of approximately 20.43% compared to G-PCC on 8iVFB. In the challenging out-of-distribution scenario Cat1B, our method achieves a Bpp reduction of approximately 57.85% compared to UniPCGC. And our method exhibits a superior time-rate trade-off, achieving an average Bpp reduction of 15.193% relative to the LINR-PCGC on 8iVFB. Figure 1 : Principle comparison of Pretrained-based, INR-based, and our Hybrid approaches, highlighting the model components utilized during the Pretrain, Overfit, and Test phases. 1 Introduction With the development of 3D sensing technology and computational power, point clouds have become a core data format for numerous critical applications, such as autonomous driving [ 34 , 38 ] , Virtual Reality (VR), Augmented Reality (AR), and digital twins [ 3 , 17 ] . Their massive data volume, however, poses significant challenges for storage and transmission [ 3 , 25 , 17 , 34 , 7 ] . Efficient point cloud compression (PCC) is therefore imperative. In general, point clouds consist of geometry and attributes, with geometry information serving as the foundation of point cloud data [ 36 ] , and lossless geometry compression is particularly crucial for applications that require the preservation of original data precision. Current mainstream Point Cloud Geometry Compression (PCGC) methods can be divided into three categories. First, traditional methods, such as the MPEG G-PCC [ 13 , 4 , 27 ] and V-PCC [ 19 , 14 ] , are highly stable and interpretable. Their primary limitation is suboptimal compression efficiency, as they rely on manually designed models that cannot fully exploit complex spatial correlations [ 7 , 12 , 11 , 16 ] . Second, pretrained-based methods leverage deep neural networks to achieve State-Of-The-Art (SOTA) compression performance on specific datasets [ 17 , 7 ] . These methods exhibit strong predictive performance when applied to data with a distribution similar to the training data, while they demonstrate significant performance degradation when applied to Out-Of-Distribution (OOD) data. The third category, Implicit Neural Representation (INR) based methods, emerged to solve this generalization problem. By overfitting a network to each data instance, they achieve stable, distribution-agnostic compression performance [ 17 , 7 , 15 , 18 , 23 , 26 , 6 , 10 ] . This paradigm, however, introduces two severe drawbacks: 1) it has to capture prior context from scratch during the overfitting stage, which makes encoding time-consuming, and 2) the overfitted network, which belongs to part of the bitstream, sometimes constitutes a relatively large portion of bitstream. There is a clear trade-off between pretrained and INR-based methods: pretrained methods are fast at inference but fail to generalize, while INR methods generalize well but have longer inference times. To address these limitations, we propose HybridINR-PCGC, a novel framework that bridges the pretrained model and INR. Our motivation is to simultaneously maintain the desired distribution-agnostic characteristics of INR while leveraging a prior from a pretrained model to accelerate the overfitting process, as depicted in Fig. 1 . The proposed method splits the overfitted network into two parts: a pretrained network and a refiner network, in which the refiner network consists of a base layer and an enhancement layer. The overall training strategy is: 1) first, train the pretrained network with the training dataset; 2) subsequently, train the refiner network with the training dataset under the prior provided by the pretrained network to derive the parameters as the base layer; 3) next, for the target point clouds, we overfit the refiner network to obtain the enhancement layer: the final parameters of the refiner network are the sum of the base and enhancement layers; 4) finally, the target point cloud is compressed by the pretrained network and the refiner network. The bitstream consists of point cloud geometry information and enhancement layer parameters. The overfitting time only includes online training of the enhancement layer. Specifically, in HybridINR-PCGC, we design a Pretrained Prior Network (PPN) as the pretrained network and a Distribution Agnostic Refiner (DAR) as the refiner network. PPN aims to provide a robust prior to accelerate the convergence of DAR and reduce the model parameters that must be transmitted. Although SOTA pretrained-based methods, such as SparsePCGC [ 30 ] or UniPCGC [ 32 ] , can be directly used as the pretrained network, these models are relatively complex and result in slow inference speed. Therefore, we design a lightweight network to implement PPN with fast inference speed and stable performance across different data distributions. It uses a feature masking operation to progressively refine its prior by incorporating previous decoded information from the DAR operating in 8 iterative stages. The DAR is a lightweight refiner network that consumes the prior from PPN and uses modules like Sparse Convolution and MLPs to refine the final occupancy prediction. Finally, we propose a Supervised Model Compression (SMC) module to supervise and minimize the bitrate allocated to the parameters of the enhancement layer, thereby further reducing the model overhead. Our main contributions to the HybridINR-PCGC framework are summarized as follows: • We propose HybridINR-PCGC, a novel framework that bridges pretrained models and INR to simultaneously resolve data dependency and high encoding time. • We design an efficient PPN for iterative 8-stage prior generation, a lightweight DAR, decomposed into a base and enhancement layer, that uses the prior for prediction, and a SMC to supervise the enhancement layer and minimize its parameter size. • Experimental results demonstrate a significantly improved compression rate and substantial savings in encoding time compared to SOTA pretrained and INR-based methods like UniPCGC and LINR-PCGC. 2 Related Work 2.1 Pretrained-based Methods Pretrained-based methods use deep neural networks to model complex spatial relationships. These methods generally fall into two main architectural categories: Voxel-based representations and Tree-based structures [ 35 ] . Voxel-based representations are often accelerated by sparse convolutions to handle the inherent sparsity of point cloud data. PCGCv2 [ 29 ] and SparsePCGC [ 30 ] introduced multiscale frameworks using sparse tensors. SparsePCGC, in particular, processes only the Most-Probable Positively-Occupied Voxels (MP-POV) using a SparseCNN-based Occupancy Probability Approximation (SOPA) model. Building on this, UniPCGC [ 32 ] and Unicorn [ 31 ] proposed versatile, unified models for diverse compression tasks within a single framework. UniPCGC, for example, introduced an Uneven 8-Stage Lossless Coder (UELC) and a Variable Rate and Complexity Module (VRCM). Other notable works in this area have also explored multiscale deep context modeling [ 22 ] , learned convolutional transforms [ 24 ] , and various autoregressive models. Tree-based structures , such as octrees, are used to organize the data and model probabilities. OctSqueeze [ 16 ] was an early work in this direction. More recently, OctSqueeze [ 16 ] was an early work in this direction. More recently, methods have integrated attention mechanisms to capture long-range dependencies, with notable examples including OctAttention [ 11 ] and TopNet [ 34 ] . Other methods, such as EHEM [ 28 ] , OctFormer [ 8 ] , and ECM-OPCC [ 20 ] , have also advanced the state of the art in tree-based compression. While these methods demonstrate the power of learning-based priors, their reliance on a fixed, pretrained model is also their fundamental limitation [ 33 ] . 2.2 INR-based Methods To address the generalization flaw inherent in pretrained models, an alternative paradigm of Implicit Neural Representation (INR) based methods was introduced. This approach achieves distribution-agnostic compression by overfitting a compact, coordinate-based network to a single point cloud instance [ 23 , 26 , 6 , 10 ] . The set of optimized network weights then forms the compressed representation. While this per-instance optimization strategy grants excellent generalization, it introduces two critical drawbacks that have hindered its practical adoption. First, the online overfitting process is computationally expensive and amounts to complete network training, resulting in prohibitively time-consuming encoding [ 33 ] . Second, the entire set of overfitted network parameters must be quantized and encoded into the bitstream, creating significant model overhead [ 17 ] . These challenges of high encoding time and model overhead have mainly limited the application of pure INR methods to lossy compression [ 15 , 18 ] . Recent research has focused on mitigating these issues. LINR-PCGC [ 17 ] was the first to address this for lossless compression by proposing a Group of Point Cloud (GoPC) framework. This method amortizes the model overhead by overfitting and sharing a single lightweight network across a group of frames. Furthermore, it accelerates the slow online training by using the network from the previous GoPC as an effective initialization for the current one [ 17 ] . Other hybrid approaches have also emerged. AnyPcc [ 33 ] , for example, proposed an Instance-Adaptive Fine-Tuning (IAFT) strategy, which synergizes explicit and implicit paradigms. Instead of training a network from scratch, IAFT rapidly fine-tunes only a small subset of a powerful pretrained model’s weights to adapt to OOD instances [ 33 ] . However, this adaptation is restricted to the final prediction heads to keep the transmitted model overhead manageable. Lacking a mechanism to compress these model parameters, the framework cannot afford deeper fine-tuning. This limited adaptation scope may reduce robustness against challenging OOD data, motivating our hybrid approach, which explicitly manages this trade-off. These works demonstrate a clear trend toward hybrid solutions that seek to combine the fast inference of pretrained models with the generalization capabilities of INR. 3 Preliminary 3.1 Group of Point Cloud (GoPC) The point cloud sequence is defined as S = { x 1 , … , x t , … , x m } S=\{x_{1},\dots,x_{t},\dots,x_{m}\} , where m m is the total number of frames. Each frame x t x_{t} at time index t t is composed of { C t , F t } \{C_{t},F_{t}\} , representing the coordinates of occupied points ( C t C_{t} ) and their associated attributes ( F t F_{t} ), respectively. Since the focus is on coordinate compression, F t F_{t} is initialized as an all-ones vector. The sequence S S is then uniformly partitioned into multiple Groups of Point Cloud (GoPCs) , such that G r = { x ( r − 1 ) ​ T + 1 , … , x m } G_{r}=\{x_{(r-1)T+1},\dots,x_{m}\} represents the r r -th GoPC, with T T being the fixed length of each group. Point clouds within the same GoPC have no interdependent relationship and are only used to share the overfitting time and network parameters. Therefore, in the following part, we use x x to simplify the expression of x t x_{t} . 3.2 Octree Bottom-Up construction Figure 2 : Concept in octree. The Bottom-Up Octree construction shown in Fig. 2 is a core data structure for most point cloud coders. Each node is associated with a single-bit occupancy code, 0 for non-occupied and 1 for occupied. We call the octree levels as “spatial scales”, and Downsampling from a high scale x i x^{i} (child nodes) to a low scale x i + 1 x^{i+1} (parent nodes) is functionally equivalent to a Max Pooling operation with a 2 3 2^{3} kernel. x i , j x^{i,j} denotes the j-th child node of all nodes at scale i i (e.g., the blue line in Fig. 2 represents all first child nodes, which are marked as x i , 1 x^{i,1} ). Most learning-based PCGC methods first apply this Downsampling process until a coarse representation at scale L L . Their main contribution lies in the subsequent use of Upsampling that predicts the occupancy status of each child node from its parent nodes scale-by-scale. The predicted probabilities of child nodes from parent nodes are then leveraged by an arithmetic coder to encode/decode the actual occupancy. Finally, non-occupied nodes are pruned to generate a lossless reconstruction of higher scale. The main task of our work is to improve the Upsampling operation for a better prediction of higher scale point clouds from lower scale point clouds 