Title: SeaCache: Spectral-Evolution-Aware Cache for Accelerating Diffusion Models

Abstract: Diffusion models are a strong backbone for visual generation, but their inherently sequential denoising process leads to slow inference. Previous methods accelerate sampling by caching and reusing intermediate outputs based on feature distances between adjacent timesteps. However, existing caching strategies typically rely on raw feature differences that entangle content and noise. This design overlooks spectral evolution, where low-frequency structure appears early and high-frequency detail is refined later. We introduce Spectral-Evolution-Aware Cache (SeaCache), a training-free cache schedule that bases reuse decisions on a spectrally aligned representation. Through theoretical and empirical analysis, we derive a Spectral-Evolution-Aware (SEA) filter that preserves content-relevant components while suppressing noise. Employing SEA-filtered input features to estimate redundancy leads to dynamic schedules that adapt to content while respecting the spectral priors underlying the diffusion model. Extensive experiments on diverse visual generative models and the baselines show that SeaCache achieves state-of-the-art latency-quality trade-offs.

Body: SeaCache: Spectral-Evolution-Aware Cache for Accelerating Diffusion Models 1 Introduction 2 Related Work 2.1 Generative Model Acceleration 2.2 Caching-based Acceleration 3 Preliminary 3.1 Denoising Generative Models 3.2 Timestep-Aware Dynamic Caching 4 Method: SeaCache 4.1 Spectral-Evolution-Aware Filter 4.2 Spectrum-Aware Dynamic Caching 5 Experiments 5.1 Experimental Settings 5.2 Quantitative Comparison 5.3 Qualitative Comparison 5.4 Additional Analysis 6 Conclusion 7 Derivation of Optimal Linear Response Setup and assumptions. Frequency-domain MSE expansion. Optimality by differentiation. Power-law prior. 8 Runtime Overhead of SEA Filtering 9 Compatibility with Fast Inference Works 10 Additional Evaluation 10.1 Quantitative Comparison in T2V Generation 10.2 Comparison with MagCache 10.3 Qualitative Comparison in T2I Generation 10.4 Qualitative Comparison in T2V Generation 11 Limitation SeaCache: Spectral-Evolution-Aware Cache for Accelerating Diffusion Models Jiwoo Chung 1,‚Ä† Sangeek Hyun 1 MinKyu Lee 1 Byeongju Han 2 Geonho Cha 2 Dongyoon Wee 2 Youngjun Hong 2,* Jae-Pil Heo 1,* 1 Sungkyunkwan University 2 NAVER Cloud Abstract Diffusion models are a strong backbone for visual generation, but their inherently sequential denoising process leads to slow inference. Previous methods accelerate sampling by caching and reusing intermediate outputs based on feature distances between adjacent timesteps. However, existing caching strategies typically rely on raw feature differences that entangle content and noise. This design overlooks spectral evolution, where low-frequency structure appears early and high-frequency detail is refined later. We introduce Spectral-Evolution-Aware Cache (SeaCache), a training-free cache schedule that bases reuse decisions on a spectrally aligned representation. Through theoretical and empirical analysis, we derive a Spectral-Evolution-Aware (SEA) filter that preserves content-relevant components while suppressing noise. Employing SEA-filtered input features to estimate redundancy leads to dynamic schedules that adapt to content while respecting the spectral priors underlying the diffusion model. Extensive experiments on diverse visual generative models and the baselines show that SeaCache achieves state-of-the-art latency-quality trade-offs. Codes are available at github.com/jiwoogit/SeaCache . ‚Ä† ‚Ä† ‚Ä† This work was done during an internship at NAVER Cloud. ‚Ä† ‚Ä† * Co-corresponding authors. 1 Introduction Recent diffusion [ 57 , 56 , 14 , 59 , 48 ] and rectified-flow (RF) [ 16 , 38 ] models produce high-quality images and videos through iterative denoising. Despite this progress, sampling still requires tens to hundreds of steps, which turns user-facing applications into latency bound. A common remedy is to reduce the step count or the per-step cost through distillation [ 45 , 50 , 26 , 52 , 51 , 15 ] , quantization [ 76 , 8 , 54 , 70 ] , or efficient attention [ 67 , 71 , 75 , 74 , 68 ] . These approaches are effective but introduce added training overhead and dependence on task or data-specific tuning. A complementary direction exploits redundancy between consecutive steps via caching. Caching reduces the number of forward passes by reusing intermediate features from previous timesteps. Early work adopts static schedules [ 79 , 36 , 31 ] that cache features at fixed intervals along the trajectory, which yields predictable speedups. More recent methods introduce dynamic schedules [ 33 , 1 , 6 ] that decide when to reuse based on the distance between current and cached features, thereby reducing the error introduced by caching. These approaches focus on where to cache, for example which layers or blocks, while the error itself is still measured in the raw feature space. Figure 1 : Conceptual illustration and motivation of the proposed caching scheme (SeaCache) compared with previous caching schemes. The lower panel shows a denoising trajectory of a cat image where coarse low-frequency structure appears at early steps and fine high-frequency details emerge at later steps, illustrating the spectral evolution of iterative generative models. SeaCache applies a Spectral-Evolution-Aware (SEA) Filter to raw diffusion features so that the distance measure better captures timestep-aware spectral residuals between timesteps. However, these approaches measure errors directly in the raw feature space and overlook spectral evolution , a key prior underlying the denoising process. Independent of caching, prior studies [ 30 , 22 , 17 , 73 ] have provided clear evidence that diffusion models exhibit spectral evolution, where ujkearly timesteps establish low-frequency structure and later timesteps refine high-frequency detail, as also illustrated in the lower panel of Fig. 1 . From this viewpoint, spectral evolution at a given timestep can be interpreted as a change in the signal-to-noise ratio. We use the term signal for the content-carrying component that is aligned with the clean sample and mainly lies in low frequencies, and noise for the residual component that is concentrated in high frequencies and reflects stochastic variation. In this paper, we incorporate this spectral evolution, or equivalently the evolution of the signal-to-noise ratio, into cache scheduling. Rather than treating all spectral components equally, we design a cache metric that focuses on the signal component while downweighting the noise component. By grounding reuse decisions on discrepancies in the synthesized content, the resulting metric becomes less sensitive to high-frequency noise and encourages cache gating to respond to meaningful signal alignment rather than stochastic variation. To validate this idea, we conduct an oracle experiment that compares cache schedules derived from raw feature distances with those derived from distances in a signal-emphasized space. In standard caching schemes, the decision to skip or compute is based on the distance between input features at consecutive timesteps. In our oracle analysis, we instead compare consecutive output features , thereby removing input-to-output approximation error and isolating the effect of spectral filtering. Specifically, we compare two criteria: one th at measures distances after applying the SEA (Spectral-Evolution-Aware) filter, which downweights the noise component (Sec. 4.1 ), and another that uses unfiltered raw outputs, as shown in Fig. 2 . The filtered criterion yields cache decisions that more closely track the full-compute trajectory, as evidenced by consistently higher PSNR. This suggests that spectrum-aware scheduling better preserves the behavior of the original model. To this end, we propose Spectral-Evolution-Aware Cache ( SeaCache ), a simple yet effective caching scheme that encodes the spectral prior of iterative denoising models through a Spectral-Evolution-Aware (SEA) filter, as illustrated in Fig. 1 . The SEA filter provides a practical scheduling policy by allowing cache decisions to be driven by the signal component. Before measuring feature distances, SeaCache passes intermediate features through a theoretically motivated, timestep-dependent filter that modulates the frequency response along the sampling trajectory. This operation acts as a lightweight reweighting that amplifies the content-relevant signal while downweighting noise-dominated components. SeaCache is plug-and-play: it requires no architectural modification or retraining, and can be attached to existing caching policies by inserting a single filtering step before distance computation. The method is both network-agnostic and sampler-agnostic, enabling integration across diverse diffusion and rectified-flow models. In practice, SeaCache substantially reduces the number of forward passes while preserving the perceptual fidelity of the original outputs, and it consistently improves the latency-quality trade-off over prior caching schemes across experiments. Our main contributions are threefold. ‚Ä¢ We propose SeaCache , a simple yet effective caching policy that bases reuse decisions on a timestep-aligned spectral representation of the generative trajectory. ‚Ä¢ We revisit prior caching strategies and show that raw feature metrics ignore spectral evolution, while our formulation bases cache decisions on content rather than noise. ‚Ä¢ Extensive experiments on multiple visual generative models show that our method achieves better latency‚Äìquality trade-offs than prior caching baselines. (a) Latency-quality trade-off on FLUX . (b) Latency-quality trade-off on Wan2.1 1.3B . Figure 2 : Latency-quality trade-off in oracle experiments. We compare cache decisions based on raw output differences and SEA-filtered output differences (Sec. 4.1 ) on FLUX [ 29 , 28 ] and Wan2.1 1.3B [ 63 ] . The refresh ratio is the fraction of timesteps that run a full denoiser evaluation instead of reusing cached features. For each criterion, PSNR is computed between the cached sample and the corresponding full timestep (no-cache) sample, averaged over each prompt set [ 49 , 23 ] . At matched refresh ratios, the filtered criterion consistently achieves higher PSNR with respect to the full-compute trajectory, validating the effectiveness of a spectrum-aware distance for cache scheduling. 2 Related Work 2.1 Generative Model Acceleration Recent generative models [ 57 , 56 , 14 , 59 , 48 , 16 , 38 , 10 ] have advanced visual synthesis, but their multi-step denoising procedures make inference latency and computation a primary bottleneck. Step reduction methods compress the sampling trajectory using improved solvers [ 57 , 39 , 78 ] and distillation-based samplers [ 40 , 58 , 50 ] . These approaches are effective but require additional training and often modify the original model. Another line of work reduces the cost of each step through quantization [ 54 , 20 , 32 , 55 ] , efficient attention [ 67 , 71 , 75 , 12 , 13 , 47 , 74 , 68 , 3 ] , and token reduction [ 55 , 25 , 75 ] . These techniques lower FLOPs while preserving the sequential dependency of the sampler, but they typically demand extra resources and engineering effort. This limitation motivates caching-based acceleration, which exploits redundancy across successive timesteps to reuse intermediate features without additional training. 2.2 Caching-based Acceleration Caching-based acceleration reuses intermediate computations across adjacent timesteps without retraining. Early methods [ 42 , 31 , 66 ] achieve speedups by reusing features but are designed for U-Net architectures, which limits their applicability to transformer-based models. To address this limitation, later work [ 9 , 53 , 34 ] adapts caching to DiT architectures [ 53 , 31 ] for image synthesis. For video, PAB [ 79 ] selects different timestep intervals for each attention block and achieves speedups. These methods rely on static schedules and cannot adapt to input diversity, so recent work adopts dynamic policies that respond to the generated signal [ 37 , 41 , 24 , 33 , 43 , 2 ] . For example, AdaCache [ 24 ] accounts for motion complexity for accelerating video generation. TeaCache [ 33 ] and DiCache [ 6 ] estimate output changes from distances measured near the input features and assume that these distances provide a reliable redundancy signal between adjacent-timesteps. In our work, we measure redundancy in a timestep-aligned spectral space that emphasizes content-carrying components. Unlike prior dynamic caching, SeaCache explicitly models spectral evolution through a timestep-conditioned SEA filter motivated by a linear-denoiser view, and applies gain normalization to enable stable distance measurements across timesteps. As a result, SeaCache is the first caching policy that injects an explicit frequency prior into the reuse decision. Recent studies [ 81 , 35 , 37 ] explore reusing features differently across frequency bands. In contrast, we focus on when to reuse rather than how to utilize cached features. Leveraging the spectral evolution prior where low-frequency structure emerges early while high-frequency details are refined later, we propose a simple cache policy that plugs easily into existing caching baselines. 3 Preliminary 3.1 Denoising Generative Models Diffusion probabilistic models (DPMs) [ 21 ] and rectified flow (RF) models [ 38 ] generate samples by iteratively removing noise. Let X X denote a clean image or video, and let an encoder map X X to a latent x 0 x_{0} . For images, we denote x 0 ‚àà ‚Ñù H √ó W √ó C x_{0}\in\mathbb{R}^{H\times W\times C} , and for videos x 0 ‚àà ‚Ñù H √ó W √ó F √ó C x_{0}\in\mathbb{R}^{H\times W\times F\times C} , where H , W , F , H,W,F, and C C denote the height, width, number of frames, and channels of the latent representation, respectively. We adopt the standard forward noising model at discrete solver steps t ‚àà { 0 , ‚Ä¶ , T } t\in\{0,\ldots,T\} : x t = a t ‚Äã x 0 + b t ‚Äã Œµ , Œµ ‚àº ùí© ‚Äã ( 0 , ùêà ) , x_{t}\;=\;a_{t}x_{0}+b_{t}\varepsilon,\qquad\varepsilon\sim\mathcal{N}(0,\mathbf{I}), (1) where T T is the total number of steps and ( a t , b t ) (a_{t},b_{t}) are determined by the noise schedule. For DPMs [ 21 ] , a t = Œ± ¬Ø t a_{t}=\sqrt{\bar{\alpha}_{t}} and b t = 1 ‚àí Œ± ¬Ø t b_{t}=\sqrt{1-\bar{\alpha}_{t}} with Œ± ¬Ø t ‚àà [ 0 , 1 ] \bar{\alpha}_{t}\in[0,1] given by the schedule. For RFs [ 38 ] , the same linear mixture provides a useful approximation with a t = 1 ‚àí Œ± t a_{t}=1-\alpha_{t} and b t = Œ± t b_{t}=\alpha_{t} , where Œ± t = t T \alpha_{t}=\tfrac{t}{T} . Under this noise mixture model, DPMs are trained to predict the noise Œµ \varepsilon from the noised latent x t x_{t} at timestep t t . The corresponding training objective is ‚Ñí DPM = ùîº x 0 , t , Œµ , y ‚Äã [ ‚Äñ Œµ ‚àí œµ Œ∏ ‚Äã ( x t , t , y ) ‚Äñ 2 2 ] , \mathcal{L}_{\text{DPM}}=\mathbb{E}_{x_{0},\,t,\,\varepsilon,\,y}\big[\big\|\varepsilon-\epsilon_{\theta}(x_{t},t,y)\big\|_{2}^{2}\big], (2) where y y is a conditioning signal and œµ Œ∏ \epsilon_{\theta} is a denoising network that estimates the noise added to x 0 x_{0} . Sampling proceeds in reverse, starting from x T ‚âà Œµ x_{T}\approx\varepsilon and iteratively reconstructing x 0 x_{0} . This iterative denoising process induces strong redundancy between outputs at adjacent timesteps, and cache-based acceleration exploits this redundancy by reusing intermediate predictions. 3.2 Timestep-Aware Dynamic Caching A recent approach, TeaCache [ 33 ] , quantifies change at step t t using the timestep-modulated input I t = œï ‚Äã ( x t , t ) I_{t}=\phi(x_{t},t) , where œï \phi injects a timestep embedding into the input x t x_{t} . This proxy is strongly correlated with the denoiser output O t O_{t} while remaining inexpensive to compute, and for brevity we refer to I t I_{t} as the input feature. The relative ‚Ñì 1 \ell_{1} distance is then defined as Œî t = L1 rel ‚Äã ( I t , I t + 1 ) = ‚à• I t ‚àí I t + 1 ‚à• 1 ‚à• I t + 1 ‚à• 1 + Œæ , \Delta_{t}=\mathrm{L1}_{\mathrm{rel}}(I_{t},I_{t+1})=\frac{\lVert I_{t}-I_{t+1}\rVert_{1}}{\lVert I_{t+1}\rVert_{1}+\xi}, (3) with a small constant Œæ \xi for numerical 