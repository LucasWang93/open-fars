Title: MM-NeuroOnco: A Multimodal Benchmark and Instruction Dataset for MRI-Based Brain Tumor Diagnosis

Abstract: Accurate brain tumor diagnosis requires models to not only detect lesions but also generate clinically interpretable reasoning grounded in imaging manifestations, yet existing public datasets remain limited in annotation richness and diagnostic semantics. To bridge this gap, we introduce MM-NeuroOnco, a large-scale multimodal benchmark and instruction-tuning dataset for brain tumor MRI understanding, consisting of 24,726 MRI slices from 20 data sources paired with approximately 200,000 semantically enriched multimodal instructions spanning diverse tumor subtypes and imaging modalities. To mitigate the scarcity and high cost of diagnostic semantic annotations, we develop a multi-model collaborative pipeline for automated medical information completion and quality control, enabling the generation of diagnosis-related semantics beyond mask-only annotations. Building upon this dataset, we further construct MM-NeuroOnco-Bench, a manually annotated evaluation benchmark with a rejection-aware setting to reduce biases inherent in closed-ended question formats. Evaluation across ten representative models shows that even the strongest baseline, Gemini 3 Flash, achieves only 41.88% accuracy on diagnosis-related questions, highlighting the substantial challenges of multimodal brain tumor diagnostic understanding. Leveraging MM-NeuroOnco, we further propose NeuroOnco-GPT, which achieves a 27% absolute accuracy improvement on diagnostic questions following fine-tuning. This result demonstrates the effectiveness of our dataset and benchmark in advancing clinically grounded multimodal diagnostic reasoning. Code and dataset are publicly available at: https://github.com/gfnnnb/MM-NeuroOnco

Body: MM-NeuroOnco: A Multimodal Benchmark and Instruction Dataset for MRI-Based Brain Tumor Diagnosis 1 Introduction 2 Related Work 2.1 Brain Tumor Datasets and Benchmarks 2.2 Challenges in Medical Evaluation Paradigms 3 MM-NeuroOnco Dataset Construction 3.1 Data Curation Standardization 3.2 Semantic Attribute Extraction Morphology. Localization. Spatial Spread. 3.3 Multi-Model Refinement Quality Control 3.4 Instruction Data Construction 4 MM-NeuroOnco Dataset Analysis 4.1 Instruction Dataset Statistics 4.2 Benchmark Composition 5 MM-NeuroOnco Bench 5.1 Rejection-Aware Evaluation Strategy 5.2 Evaluation Metrics 6 Experiments 6.1 Experimental Setup 6.2 Evaluation Results 6.3 Ablation Study 6.4 Case Study 7 Conclusion 8 Limitations and Ethical Considerations MM-NeuroOnco: A Multimodal Benchmark and Instruction Dataset for MRI-Based Brain Tumor Diagnosis Feng Guo guofeng@gdiist.cn Guangdong Institute of Intelligence Science and Technology Hengqin China , Jiaxiang Liu liujiaxiang@gdiist.cn Guangdong Institute of Intelligence Science and Technology Hengqin China , Yang Li liyang@gdiist.cn Guangdong Institute of Intelligence Science and Technology Hengqin China , Qianqian Shi qqshi@mail.tsinghua.edu.cn Center for Brain-Inspired Computing Research (CBICR), Department of Precision Instrument, Tsinghua University Beijing China and Mingkun Xu xumingkun@gdiist.cn Guangdong Institute of Intelligence Science and Technology Hengqin China (2018) Abstract. Accurate brain tumor diagnosis requires models to not only detect lesions but also generate clinically interpretable reasoning grounded in imaging manifestations, yet existing public datasets remain limited in annotation richness and diagnostic semantics. To bridge this gap, we introduce MM-NeuroOnco , a large-scale multimodal benchmark and instruction-tuning dataset for brain tumor MRI understanding, consisting of 24,726 MRI slices from 20 data sources paired with approximately 200,000 semantically enriched multimodal instructions spanning diverse tumor subtypes and imaging modalities. To mitigate the scarcity and high cost of diagnostic semantic annotations, we develop a multi-model collaborative pipeline for automated medical information completion and quality control, enabling the generation of diagnosis-related semantics beyond mask-only annotations. Building upon this dataset, we further construct MM-NeuroOnco-Bench , a manually annotated evaluation benchmark with a rejection-aware setting to reduce biases inherent in closed-ended question formats. Evaluation across ten representative models shows that even the strongest baseline, Gemini 3 Flash, achieves only 41.88% accuracy on diagnosis-related questions, highlighting the substantial challenges of multimodal brain tumor diagnostic understanding. Leveraging MM-NeuroOnco, we further propose NeuroOnco-GPT , which achieves a 27% absolute accuracy improvement on diagnostic questions following fine-tuning. This result demonstrates the effectiveness of our dataset and benchmark in advancing clinically grounded multimodal diagnostic reasoning. Code and dataset are publicly available at: https://github.com/gfnnnb/MM-NeuroOnco . Instruction Dataset, Medical Benchmark, Multimodal Large Language Models, Neuro-Oncology † † copyright: acmlicensed † † journalyear: 2018 † † doi: XXXXXXX.XXXXXXX † † conference: Make sure to enter the correct conference title from your rights confirmation email; June 03–05, 2018; Woodstock, NY † † isbn: 978-1-4503-XXXX-X/2018/06 † † ccs: Computing methodologies Natural language processing † † ccs: Computing methodologies Computer vision † † ccs: Computing methodologies Machine learning † † ccs: Applied computing Life and medical sciences † † ccs: Information systems Data mining 1. Introduction Brain tumors are a highly lethal class of diseases arising within the central nervous system (Bray et al. , 2024 ; Price et al. , 2024 ) . Clinical practice indicates that reliable differential diagnosis cannot be achieved through lesion localization alone, but instead requires holistic reasoning grounded in multi-dimensional imaging semantics (Csutak et al. , 2020 ) . In recent years, deep learning has achieved remarkable progress in brain tumor segmentation tasks, with paradigms such as the BraTS challenge series continuously advancing pixel-level lesion modeling capabilities (Menze et al. , 2014 ) . However, these segmentation-centric approaches primarily emphasize spatial boundary delineation, while largely overlooking the medical semantic modeling and diagnostic reasoning that are essential for clinical decision-making (Setyawan et al. , 2024 ) . High segmentation accuracy does not necessarily translate into correct understanding of tumor invasiveness, cross-modal discrepancies, or pathological implications, leaving existing models with notable limitations in real-world clinical scenarios. Figure 1. Overview of MM-NeuroOnco. The benchmark curates 24,726 slices from 20 diverse datasets. Standard diagnostic labels are augmented with fine-grained semantic attributes to construct explicit Chain-of-Thought (CoT) reasoning. This structure enables a multi-grained evaluation paradigm, covering both holistic open-ended diagnosis and targeted closed-ended Question Answering across multiple clinical categories. Overview of MM-NeuroOnco, showing dataset curation across 20 sources, semantic attribute augmentation, and CoT-style reasoning for multi-grained evaluation (open-ended diagnosis and closed-ended QA across clinical categories). In routine clinical workflows, radiologists typically base brain tumor diagnosis on a small set of highly informative two-dimensional slices, interpreted through cross-modal comparison across MRI sequences, rather than exhaustive voxel-wise analysis of full three-dimensional volumes. This slice-centered diagnostic paradigm is particularly aligned with auxiliary diagnosis and clinical settings requiring rapid diagnosis, and more closely reflects how human clinicians perform diagnostic reasoning in practice. By contrast, directly operating on full 3D volumes, while offering richer spatial context, often incurs substantial computational overhead and inference latency, limiting its practicality in efficient clinical deployment (Dorfner et al. , 2025 ) . To address these limitations, as illustrated in Figure 1 , we construct a multimodal instruction-tuning dataset and benchmark tailored for brain tumor MRI understanding. Distinct from prior works that emphasize visual recognition or coarse-grained question answering, our design focuses on high-density diagnostic semantics and structured reasoning supervision. By organizing diagnosis-relevant attributes into explicit intermediate reasoning steps, we enable models to follow clinically grounded diagnostic logic, while a more robust evaluation protocol facilitates faithful assessment of model capability boundaries and reliability in high-stakes diagnostic settings. The main contributions of this work are threefold: • Comprehensive Benchmark Dataset: We construct MM-NeuroOnco , a large-scale multimodal resource comprising 24,726 MRI slices across four modalities, covering eight tumor subtypes and healthy controls. It features approximately 200,000 semantically enriched instruction samples and includes MM-NeuroOnco-Bench , a manually annotated subset for rigorous evaluation. • Automated Semantic Completion Pipeline: We propose a novel data construction framework that leverages multi-model collaboration to generate diagnosis-relevant attributes from sparse annotations. This pipeline effectively alleviates the semantic gap and the prohibitive costs associated with large-scale expert labeling. • Specialized Model Robust Evaluation: We develop NeuroOnco-GPT , validating the practical value of our dataset. Furthermore, we introduce a rejection-aware evaluation protocol to mitigate the “forced-choice” bias inherent in closed-ended questions, enabling a more faithful assessment of model reliability and capability boundaries in high-stakes diagnostic tasks. Figure 2. The MM-NeuroOnco dataset curation pipeline, which consists of four sequential steps transforming raw MRI data into semantically enriched multimodal instructions. The MM-NeuroOnco dataset curation pipeline with four sequential steps that transform raw MRI data into semantically enriched multimodal instructions. 2. Related Work 2.1. Brain Tumor Datasets and Benchmarks Brain tumor MRI analysis has long been a focal point of medical imaging research, leading to the establishment of numerous representative public datasets and evaluation benchmarks. Early efforts concentrated predominantly on the segmentation and quantitative analysis of tumor regions, with the BraTS (Brain Tumor Segmentation) challenge series emerging as the most influential initiative (Menze et al. , 2014 ; Bakas et al. , 2017 ; Baid et al. , 2021 ; Adewole et al. , 2023 ) . By consistently releasing multi-year datasets featuring multi-modal MRI scans (e.g., T1, T2, FLAIR, T1ce) alongside fine-grained pixel-level annotations, BraTS has become the gold standard benchmark for brain tumor segmentation research (Menze et al. , 2014 ) . Beyond BraTS, The Cancer Imaging Archive (TCIA) aggregates a diverse array of brain tumor-related MRI collections. Spanning various tumor types, imaging protocols, and clinical contexts, these resources have been extensively utilized for tumor segmentation, classification, and multimodal image analysis research (Clark et al. , 2013 ) . Furthermore, the systematic curation and analysis of large-scale medical imaging datasets provide essential context for brain tumor research. For instance, Project Imaging-X conducted a systematic review of over 1,000 open medical imaging datasets, performing statistical analyses across dimensions such as modality, task, and anatomical site (Project Imaging-X Contributors, 2025 ) . Overall, these rich resources have provided essential data support for research in this field, significantly propelling its general advancement. 2.2. Challenges in Medical Evaluation Paradigms The choice of evaluation paradigm fundamentally dictates how model capabilities are characterized, yet finding a robust metric for medical reasoning remains an open challenge (He et al. , 2023 ; Liu et al. , 2024b ) . Closed-ended evaluation (e.g., multiple-choice) is widely adopted due to its reproducibility and straightforward metrics. However, this format is inherently reductionist: it collapses complex clinical reasoning into discrete options. Consequently, models often learn to exploit statistical biases in option distributions or language priors rather than grounding their answers in imaging evidence, leading to inflated performance scores that do not reflect true diagnostic capability (Ye et al. , 2024 ; Yue et al. , 2024 ) . Conversely, open-ended generation offers a broader response space better suited for assessing reasoning coherence. Yet, it suffers from metric instability. Determining semantic equivalence between a model’s output and a reference answer is notoriously difficult, and standard metrics (such as BLEU or ROUGE) correlate poorly with clinical accuracy (Lau et al. , 2018 ; He et al. , 2020 ) . Furthermore, generative models are prone to “hallucinations”—fabricating convincing but factually incorrect medical details—which undermines trust in automated scoring (Pal et al. , 2023 ; Xia et al. , 2024 ) . Prior works have attempted to bridge this divide by introducing structured constraints, auxiliary supervision, or explicit reasoning traces (Gai et al. , 2024 ; Liu et al. , 2024a ; Wang et al. , 2025 ) . Despite these efforts, faithfully characterizing diagnostic reasoning while maintaining evaluation reproducibility remains an unresolved bottleneck, particularly in brain tumor scenarios where imaging semantics are highly specialized and subtle. 3. MM-NeuroOnco Dataset Construction The construction of MM-NeuroOnco follows a rigorous four-stage pipeline designed to transform raw, heterogeneous MRI collections into a semantically dense instruction-tuning dataset. The overall workflow is illustrated in Figure 2 . 3.1. Data Curation Standardization We aggregated a massive corpus of over 100,000 brain MRI scans from disparate public repositories, including Kaggle, Zenodo, and TCIA. Raw data from these sources suffered from severe heterogenei-ty—ranging from inconsistent modality tagging and chaotic file structures to non-standardized diagnostic labels. To resolve this, we designed a Unified Metadata Schema, converting all samples into a standardized JSON index format. This step effectively eliminates structural discrepancies, establishing a single, consistent access point for diverse data sources. Following strict deduplication and quality filtering, we established a “Full Master Index” containing 73,226 valid samples, of which 19,086 are paired with pixel-level segmentation masks. This Master Index underpins semantic completion and task sampling, forming the basis of both the MM-NeuroOnco training set and the evaluation benchmark. Figure 3. Radar chart comparing the performance of the base model and different fine-tuning strategies on MM-NeuroOnco-Bench. Performance comparison on both closed-ended and open-ended QA across multiple LVLMs. 3.2. Semantic Attribute Extraction A core challenge in medical VQA is bridging the gap between low-level pixel cues and high-level linguistic reasoning. To address this, we implement an annotation-based semantic conversion pipeline inspired by Vepa et al. (Murari Vepa et al. , 2025 ) . We translate pixel-level tumor masks into structured semantic attributes via a deterministic geometric mapping. Specifically, we extract morphology, localization, and spatial spread descriptors as follows. Morphology. We quantify lesion shape compactness using the circularity metric: (1) C = 4 ​ π ​ A P 2 , \small C=\frac{4\pi A}{P^{2}}, where A A and P P denote the lesion area and perimeter, respectively. Lower values of C C indicate increased shape irregularity. Localization. The lesion centroid is computed from spatial image moments as: (2) C x = M 1 , 0 M 0 , 0 , C y = M 0 , 1 M 0 , 0 , \small C_{x}=\frac{M_{1,0}}{M_{0,0}},\quad C_{y}=\frac{M_{0,1}}{M_{0,0}}, where the ( p , q ) (p,q) -th order moment is defined as (3) M p ​ q = ∑ x ∑ y x p ​ y q ​ I ​ ( x , y ) , \small M_{pq}=\sum_{x}\sum_{y}x^{p}y^{q}I(x,y), with I ​ ( x , y ) I(x,y) denoting the binary lesion mask. This descriptor encodes the spatial position of the lesion within the imaging plane. Spatial Spread. To capture lesion multifocality, we define the dominant component ratio: (4) f c ​ o ​ r ​ e = A max ∑ i A i , \small f_{core}=\frac{A_{\max}}{\sum_{i}A_{i}}, where A i A_{i} denotes the area of the i i -th connected component and A max A_{\max} corresponds to the largest one. Lower values indicate increased spatial dispersion. Based on standardized thresholds (e.g., C 0.5 C 0.5 for irregular morphology), these me