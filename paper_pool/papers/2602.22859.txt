Title: From Blind Spots to Gains: Diagnostic-Driven Iterative Training for Large Multimodal Models

Abstract: As Large Multimodal Models (LMMs) scale up and reinforcement learning (RL) methods mature, LMMs have made notable progress in complex reasoning and decision making. Yet training still relies on static data and fixed recipes, making it difficult to diagnose capability blind spots or provide dynamic, targeted reinforcement. Motivated by findings that test driven error exposure and feedback based correction outperform repetitive practice, we propose Diagnostic-driven Progressive Evolution (DPE), a spiral loop where diagnosis steers data generation and reinforcement, and each iteration re-diagnoses the updated model to drive the next round of targeted improvement. DPE has two key components. First, multiple agents annotate and quality control massive unlabeled multimodal data, using tools such as web search and image editing to produce diverse, realistic samples. Second, DPE attributes failures to specific weaknesses, dynamically adjusts the data mixture, and guides agents to generate weakness focused data for targeted reinforcement. Experiments on Qwen3-VL-8B-Instruct and Qwen2.5-VL-7B-Instruct show stable, continual gains across eleven benchmarks, indicating DPE as a scalable paradigm for continual LMM training under open task distributions. Our code, models, and data are publicly available at https://github.com/hongruijia/DPE.

Body: From Blind Spots to Gains: Diagnostic-Driven Iterative Training for Large Multimodal Models 1 Introduction 2 Related Work 2.1 Reasoning with Large Multimodal Models 2.2 Self-Evolving Multimodal Frameworks 3 Methods 3.1 Overall Framework 3.2 Diagnostic Mechanism Diagnostic sampling and step-aware scoring. Failure attribution and diagnostic summary. From diagnosis to category proportions. Structured diagnostic report. 3.3 Multiple Agents Questioner System Category quota constraint and dataset formalization. Planner Agent. Image Selector Agent. Question Generator Agent. Validation Agent. 3.4 LMM Training Group-normalized advantages. A maximum-entropy view of learnability. Iterative training. 4 Experiments 4.1 Experiment Settings DPE Settings. Baselines Evaluation Protocol 4.2 Main Results 4.3 Ablation Studies Impact of Static Data. Impact of the diagnostic module. Validating diagnosis-guided data distribution. Impact of image retrieval and editing. 4.4 Diversity Analysis Text diversity. Visual diversity. 4.5 Quality Analysis of Generated Questions 5 Conclusion A Case Study From Blind Spots to Gains: Diagnostic-Driven Iterative Training for Large Multimodal Models Hongrui Jia Chaoya Jiang Shikun Zhang Wei Ye Abstract As Large Multimodal Models (LMMs) scale up and reinforcement learning (RL) methods mature, LMMs have made notable progress in complex reasoning and decision making. Yet training still relies on static data and fixed recipes, making it difficult to diagnose capability blind spots or provide dynamic, targeted reinforcement. Motivated by findings that test driven error exposure and feedback based correction outperform repetitive practice, we propose Diagnostic-driven Progressive Evolution (DPE), a spiral loop where diagnosis steers data generation and reinforcement, and each iteration re-diagnoses the updated model to drive the next round of targeted improvement. DPE has two key components. First, multiple agents annotate and quality control massive unlabeled multimodal data, using tools such as web search and image editing to produce diverse, realistic samples. Second, DPE attributes failures to specific weaknesses, dynamically adjusts the data mixture, and guides agents to generate weakness focused data for targeted reinforcement. Experiments on Qwen3-VL-8B-Instruct and Qwen2.5-VL-7B-Instruct show stable, continual gains across eleven benchmarks, indicating DPE as a scalable paradigm for continual LMM training under open task distributions. Our code, models, and data are publicly available at https://github.com/hongruijia/DPE . Large Multimodal Models, Diagnostic-driven, Iterative ‚Ä† ‚Ä† 1 Introduction In recent years, as reinforcement learning methods ( Guo et al. , 2025 ; Zheng et al. , 2025 ; Yu et al. , 2025 ; Zhao et al. , 2025 ; Gao et al. , 2025 ) have matured, the reasoning capabilities of Large Multimodal Models (LMMs) have improved substantially. Models such as GPT-5.2 ( OpenAI Team , 2025 ) , Claude Sonnet 4.5 ( Anthropic Team , 2025 ) , and Qwen3-VL ( Bai et al. , 2025a ) show particularly strong performance on complex reasoning tasks. However, annotated data for multimodal reasoning remains scarce, making it difficult to support large scale training of LMMs ( Liu et al. , 2025a ) . To mitigate this, prior works ( He et al. , 2025 ; Chen et al. , 2025a ; Liu et al. , 2024 ; Thawakar et al. , 2025 ; Sunil et al. , 2026 ; Liu et al. , 2025b ) have proposed self-evolving training frameworks characterized by an iterative cycle of self-questioning and self-answering to continuously refine the model . While these approaches have garnered significant attention, current methodologies are constrained by two fundamental limitations: 1. Lack of Interpretable Diagnostics. Driven by heuristic signals (e.g., perplexity) rather than explicit failure attribution, existing methods lack a principled capability decomposition. Consequently, the evolutionary process pursues superficial complexity instead of addressing genuine capability gaps, resulting in unstable data quality and noise. 2. Scarcity of Visual Diversity. Reliance on static image sets inherently restricts the semantic scope of training. While textual queries evolve, the immutable visual context limits the coverage of long-tail scenarios, causing performance on rare or complex concepts to plateau or even regress. Figure 1 : Due to the lack of interpretable diagnostics and scarcity of visual diversity, previous self-evolution frameworks can alleviate hallucination to some extent but fail to provide meaningful improvements on long-tail tasks such as mathematics and OCR. As a result, the model often exhibits instability or even degradation in these capabilities during the evolution process. In contrast, our DPE framework effectively addresses these blind spots and supports a more comprehensive and balanced progression of the model‚Äôs abilities. Research in educational psychology ( Black Wiliam , 1998 ; Hattie Timperley , 2007 ) reveals that diagnosis and targeted correction are the pivotal determinants of learning efficiency. Inspired by this ‚Äùdiagnose-and-correct‚Äù mechanism in human cognition, we propose Diagnostic-driven Progressive Evolution (DPE) . Mirroring these principles, DPE eschews indiscriminate data expansion. Instead, it prioritizes the diagnosis of capability gaps to steer targeted data generation and mixture optimization, effectively breaking the multimodal long-tail bottleneck. Specifically, DPE consists of two key mechanisms: (1)Adaptive Diagnosis. Before generating new data, a diagnostic agent analyzes the model‚Äôs failure patterns to identify specific weaknesses and capability blind spots. These insights are used to dynamically optimize the training data mixture, driving a closed loop of diagnosis, generation, and reinforcement for targeted capability improvement. (2) Tool-Use Data Evolution. Instead of relying on static datasets or template-based text rewriting, DPE employs a multi-agent system equipped with image search and editing tools. These agents collaboratively source and annotate diverse visual content from external pools, allowing the framework to construct high-quality, weakness-focused training samples with deliberately controlled distributions. Crucially, DPE is not constrained by a static dataset. It can adaptively source images from large external pools and construct targeted questions to form training data with deliberately controlled mixtures for reinforcement. We apply our DPE framework to multiple models, including Qwen2.5-VL-7B-Instruct ( Bai et al. , 2025b ) and Qwen3-VL-8B-Instruct ( Bai et al. , 2025a ) , and evaluate it on 11 challenging benchmarks that probe different aspects of multimodal reasoning, including MMMU ( Yue et al. , 2024b ) , CharXiv ( Wang et al. , 2024b ) , and MathVision ( Wang et al. , 2024a ) . Experiments show that, compared with static data training methods, our framework can improve model capabilities broadly using only a small amount of training data. Further analysis indicates that, as training iterates, the diagnosis mechanism noticeably improves training stability, while the unlabeled multimodal annotation mechanism effectively alleviates bottlenecks caused by static data. Our main contributions are as follows: ‚Ä¢ We propose a novel Diagnostic-driven Progressive Evolution (DPE) training paradigm that targets model blind spots through a diagnosis, generation, and reinforcement loop, mitigating diminishing marginal returns during training and avoiding long tail coverage issues induced by static data. ‚Ä¢ We demonstrate the efficiency of DPE on multiple open source models. With only 1000 training examples, it achieves broad improvements in multimodal reasoning. ‚Ä¢ We provide systematic analyses that quantitatively evaluate how the diagnosis mechanism affects training stability, offering a new direction for addressing long tail challenges in improving multimodal reasoning. 2 Related Work 2.1 Reasoning with Large Multimodal Models The success of reinforcement learning (RL) in enhancing the reasoning capabilities of Large Language Models (LLMs) ( Guo et al. , 2025 ; Zheng et al. , 2025 ; Zhao et al. , 2025 ) has spurred similar advancements in Large Multimodal Models (LMMs). Recent works focus on establishing verifiable reward mechanisms to align visual reasoning. For instance, VLM-R1 ( Shen et al. , 2025 ) and RRVF ( Chen et al. , 2025b ) introduce rule-based and rendering-based feedback loops, respectively, to ground reasoning in verifiable signals. Others, such as Vision-SR1 ( Li et al. , 2025b ) and SRPO ( Wan et al. , 2025 ) , leverage self-consistency and self-reflection to mitigate hallucinations and refine reasoning trajectories. OVR ( Wei et al. , 2025 ) further explores cold-start strategies to transfer cognitive behaviors from language to vision. Despite these strides, most RL-based LMMs rely heavily on static datasets or expensive annotations. They often lack the mechanism to dynamically adapt the data distribution to the model‚Äôs evolving capabilities, leading to inefficiencies where models over-train on mastered samples while neglecting long-tail weaknesses. 2.2 Self-Evolving Multimodal Frameworks To address data scarcity, self-evolving paradigms ( He et al. , 2025 ; Chen et al. , 2025a ; Liu et al. , 2024 ) have emerged, where models improve via self-generated feedback. Existing approaches can be broadly categorized into filtering-based and generative methods. Filtering strategies, such as M-STAR ( Liu et al. , 2024 ) and EvoLMM ( Thawakar et al. , 2025 ) , utilize uncertainty metrics (e.g., entropy) or process reward models to select high-quality samples from noisy generations. Generative frameworks, exemplified by VisPlay ( He et al. , 2025 ) and IREASONER ( Sunil et al. , 2026 ) , employ a proposer-solver loop where a generator creates new queries and a solver verifies them using consistency checks. More recent agentic approaches ( Liu et al. , 2025b ; Pan et al. , 2025 ) incorporate tool-use and multi-agent collaboration to enhance the reliability of self-evaluation. However, a critical limitation remains: current self-evolving pipelines typically operate in a ‚Äùblind‚Äù manner. They generate or filter data based on general quality metrics rather than explicitly diagnosing the model‚Äôs specific failure modes. This often results in distribution drift or mode collapse during iterations, as the generated data fails to target the model‚Äôs actual cognitive blind spots. 3 Methods 3.1 Overall Framework Figure 2 : Overview of the DPE framework. As shown in Figure 2 , we propose Diagnostic-driven Progressive Evolution (DPE) , a closed-loop training framework that steadily improves large multimodal models (LMMs) under scarce multimodal supervision and long-tail coverage gaps. Different from prior self-evolution methods that depend on static image sets and heuristic signals, DPE iteratively performs diagnosis , targeted generation , and reinforcement-based updating . In each iteration, DPE explicitly controls both the training-data category composition and question emphasis, aligning training resources with current capability blind spots and reducing instability and diminishing returns on long-tail skills. Let the policy at iteration k k be œÄ Œ∏ ( k ) \pi_{\theta^{(k)}} . DPE constructs a training set ùíØ ( k ) \mathcal{T}^{(k)} and updates parameters to Œ∏ ( k + 1 ) \theta^{(k+1)} via reinforcement learning with verifiable rewards: Œ∏ ( k + 1 ) = ùíú RL ‚Äã ( Œ∏ ( k ) ; ùíØ ( k ) ) , ùíØ ( k ) = ùíú gen ‚Äã ( ‚Ñõ ( k ) ) , ‚Ñõ ( k ) = ùíú diag ‚Äã ( œÄ Œ∏ ( k ) ) , \scriptstyle\theta^{(k+1)}=\mathcal{A}_{\text{RL}}\!\left(\theta^{(k)};\ \mathcal{T}^{(k)}\right),\mathcal{T}^{(k)}=\mathcal{A}_{\text{gen}}\!\left(\mathcal{R}^{(k)}\right),\mathcal{R}^{(k)}=\mathcal{A}_{\text{diag}}\!\left(\pi_{\theta^{(k)}}\right), (1) where ùíú diag \mathcal{A}_{\text{diag}} , ùíú gen \mathcal{A}_{\text{gen}} , and ùíú RL \mathcal{A}_{\text{RL}} are the diagnosis, generation, and RL-update operators, respectively, and ‚Ñõ ( k ) \mathcal{R}^{(k)} is a structured diagnostic report. 3.2 Diagnostic Mechanism The diagnostic mechanism provides an interpretable and actionable assessment of the current policy œÄ Œ∏ ( k ) \pi_{\theta^{(k)}} at the start of each iteration, and converts it into constraints/instructions for the next-round data generation. Instead of heuristic proxies (e.g., perplexity or reward averages), our diagnosis performs explicit failure attribution and capability decomposition : it identifies where the model fails, which capability dimension is responsible, and recurring error patterns, enabling stable targeted evolution. We map multimodal logical reasoning into a capability space ùíû = { c 1 , c 2 , ‚Ä¶ , c K } \mathcal{C}=\{c_{1},c_{2},\ldots,c_{K}\} with K = 12 K=12 dimensions, including geometry images, medical images, statistical charts, text-intensive images, flow diagrams, mathematical formulas, spatial maps, natural scenes, daily objects, artworks, architectural images, and others. Diagnostic sampling and step-aware scoring. At iteration k k , we sample N = 200 N=200 instances from a diagnostic pool ùíü diag \mathcal{D}_{\text{diag}} : { ( I n , q n , a n , c n ) } n = 1 N ‚àº ùíü diag . \{(I_{n},q_{n},a_{n},c_{n})\}_{n=1}^{N}\sim\mathcal{D}_{\text{diag}}. (2) The model produces y ^ n ‚àº œÄ Œ∏ ( k ) ( ‚ãÖ ‚à£ I n , q n ) \hat{y}_{n}\sim\pi_{\theta^{(k)}}(\cdot\mid I_{n},q_{n}) , which is scored by diagnostic agents: z n = v ‚Äã ( y ^ n , a n ) , z_{n}=v(\hat{y}_{n},a_{n}), (3) where v ‚Äã ( ‚ãÖ ) v(\cdot) evaluates both reasoning steps and final results; we convert z n z_{n} into a scalar correctness signal for aggregation. For each category c c , we compute counts and accuracy: N c = ‚àë n = 1 N ùïÄ ‚Äã [ c n = c ] , Acc c = 1 N c ‚Äã ‚àë n = 1 N ùïÄ ‚Äã [ c n = c ] ‚ãÖ z n . N_{c}=\sum_{n=1}^{N}\mathbb{I}[c_{n}=c],\qquad\mathrm{Acc}_{c}=\frac{1}{N_{c}}\sum_{n=1}^{N}\mathbb{I}[c_{n}=c]\cdot z_{n}. Failure attribution and diagnostic summary. Beyond category accuracy, agents analyze the error set ‚Ñ∞ c = { n ‚à£ c n = c , z n = 0 } \mathcal{E}_{c}=\{n\mid c_{n}=c,\ z_{n}=0\} and summarize recurring patterns as ‚Ñ± c \mathcal{F}_{c} (e.g., OCR: missing lines/misaligned regions; charts: ignored axis units/legend mismatch; math: dropped steps/symbol parsing errors; multi-image: entity misalignment/incorrect reference resolution). These attributions are injected into generation as executable prompts to control focus and difficulty. From diagnosis to category proportions. A key output is the category proportion vector ùú∂ ( k ) \boldsymbol{\alpha}^{(k)} for next-round generation. We assign unnormalized weights Œ± ~ c \tilde{\alpha}_{c} according to segmented ranges of Acc c \mathrm{Acc}_{c} , and normalize: Œ± c ( k ) = Œ± ~ c ‚àë c ‚Ä≤ = 1 C Œ± ~ c ‚Ä≤ . \alpha_{c}^{(k)}=\frac{\tilde{\alpha}_{c}}{\sum_{c^{\prime}=1}^{C}\tilde{\alpha}_{c^{\prime}}}. (4) Structured diagnostic report. The final report is ‚Ñõ ( k ) = ( ùú∂ ( k ) , { ‚Ñ± c ( k ) } c = 1 C , { ‚Ñã c ( k ) } c = 1 C ) , \mathcal{R}^{(k)}=\