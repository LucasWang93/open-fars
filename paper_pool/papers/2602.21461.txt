Title: VecGlypher: Unified Vector Glyph Generation with Language Models

Abstract: Vector glyphs are the atomic units of digital typography, yet most learning-based pipelines still depend on carefully curated exemplar sheets and raster-to-vector postprocessing, which limits accessibility and editability. We introduce VecGlypher, a single multimodal language model that generates high-fidelity vector glyphs directly from text descriptions or image exemplars. Given a style prompt, optional reference glyph images, and a target character, VecGlypher autoregressively emits SVG path tokens, avoiding raster intermediates and producing editable, watertight outlines in one pass. A typography-aware data and training recipe makes this possible: (i) a large-scale continuation stage on 39K noisy Envato fonts to master SVG syntax and long-horizon geometry, followed by (ii) post-training on 2.5K expert-annotated Google Fonts with descriptive tags and exemplars to align language and imagery with geometry; preprocessing normalizes coordinate frames, canonicalizes paths, de-duplicates families, and quantizes coordinates for stable long-sequence decoding. On cross-family OOD evaluation, VecGlypher substantially outperforms both general-purpose LLMs and specialized vector-font baselines for text-only generation, while image-referenced generation reaches a state-of-the-art performance, with marked gains over DeepVecFont-v2 and DualVector. Ablations show that model scale and the two-stage recipe are critical and that absolute-coordinate serialization yields the best geometry. VecGlypher lowers the barrier to font creation by letting users design with words or exemplars, and provides a scalable foundation for future multimodal design tools.

Body: VecGlypher: Unified Vector Glyph Generation with Language Models 1 Introduction 2 Related Works Image-referenced glyph and font generation. Text-referenced glyph and font generation. Language models for vector graphics. 3 Method 3.1 Preliminaries 3.2 Data curation Envato fonts. Google Fonts. Dataset statistics. 3.3 Dataset processing Font processing. Glyph processing. 3.4 Problem formulation Training and inference. Output space. Prompts. 3.5 Training recipe 4 Experiments 4.1 Implementation Details 4.2 Datasets and Evaluation Corpora and splits. Evaluation protocol. 4.3 Ablations Text-referenced. Image-referenced. 4.4 Comparisons to Baselines Text-referenced. Image-referenced. More qualitative results. 5 Discussions and Conclusions Discussions. Conclusions. A Dataset Statistics (Cont’) Training data before filtering. Heavy-tailed SVG sequences. Filtered test-set statistics. B Prompt Templates and Samples C Additional Metrics D Additional Baselines E Additional Qualitative Results 1]Meta AI 2]UC, Santa Cruz \contribution [*]Work done at Meta \metadata [Project Page] https://xk-huang.github.io/VecGlypher VecGlypher: Unified Vector Glyph Generation with Language Models Xiaoke Huang Bhavul Gauri Kam Woh Ng Tony Ng Mengmeng Xu Zhiheng Liu Weiming Ren Zhaochong An Zijian Zhou Haonan Qiu Yuyin Zhou Sen He Ziheng Wang Tao Xiang Xiao Han [ [ ( February 25, 2026 ) Abstract Vector glyphs are the atomic units of digital typography, yet most learning-based pipelines still depend on carefully curated exemplar sheets and raster-to-vector postprocessing, which limits accessibility and editability. We introduce VecGlypher, a single multimodal language model that generates high-fidelity vector glyphs directly from text descriptions or image exemplars. Given style prompts or reference glyph images, and a target character, VecGlypher autoregressively emits SVG path tokens, avoiding raster intermediates and producing editable, watertight outlines in one pass. A typography-aware data and training recipe makes this possible: (i) a large-scale continuation stage on 39K noisy Envato fonts to master SVG syntax and long-horizon geometry, followed by (ii) post-training on 2.5K expert-annotated Google Fonts with descriptive tags and exemplars to align language and imagery with geometry; preprocessing normalizes coordinate frames, canonicalizes paths, de-duplicates families, and quantizes coordinates for stable long-sequence decoding. On cross-family OOD evaluation, VecGlypher substantially outperforms both general-purpose LLMs and specialized vector-font baselines for text-only generation, while image-referenced generation reaches a state-of-the-art performance, with marked gains over DeepVecFont-v2 and DualVector. Ablations show that model scale and the two-stage recipe are critical and that absolute-coordinate serialization yields the best geometry. VecGlypher lowers the barrier to font creation by letting users design with words or exemplars, and provides a scalable foundation for future multimodal design tools. Figure 1 : VecGlypher generates high-fidelity vector glyphs directly as editable SVG outlines under two types of conditioning: (a) image-referenced generation, where a handful of exemplar glyph images specify the style and the model synthesizes new glyphs in the same visual form; and (b) text-referenced generation, where a natural-language prompt drives the synthesis without requiring exemplars. The figure shows the synthesized wordmark and sample vector outlines, highlighting one-pass generation of clean, controllable contours for typography workflows. 1 Introduction Vector glyphs—the parametric curves that define letters and symbols in a font—are the atomic units of digital typography. They must be resolution-independent, compact, and precisely controllable for downstream typesetting, logo design, and UI rendering. Recent learning-based approaches have begun to automate glyph creation, yet the prevailing paradigm remains image-referenced vector glyph generation : given a few exemplar raster glyphs of a font, a model synthesizes the remaining characters by predicting vector outlines ( Wang and Lian , 2021 ; Wang et al. , 2023 ; Thamizharasan et al. , 2024 ) . While effective when exemplars are carefully prepared, this workflow assumes that users can already produce or collect representative glyph images for each new style. In practice, this requirement is a major bottleneck, especially for non-experts and for rapid ideation cycles in which designers would rather describe a desired style than draft a reference sheet. We posit that natural language is a more universal and accessible interface for font creation. Designers and casual users routinely communicate typographic intent with concepts such as “high-contrast, narrow, slightly condensed, art-deco, playful” . Moreover, the output we ultimately seek, a sequence of vector drawing commands and coordinates, is itself textual (e.g., an SVG path). This observation suggests an appealing formulation: treat glyph generation as a language modeling problem and leverage multimodal Large Language Models (LLMs) ( Bai et al. , 2025 ; Team et al. , 2025 ; Liu et al. , 2023a ) to map text descriptions or image exemplars directly to vector code. Besides simplifying the human interface, this formulation stands to inherit the strong text and image understanding of modern foundation models. However, building an LLM that can actually draw credible typography is nontrivial. General-purpose LLMs ( Achiam et al. , 2023 ; Anthropic , 2024 ; Comanici et al. , 2025 ; Yang et al. , 2025a ) and off-the-shelf vector-graphics LLMs ( Rodriguez et al. , 2023 ; Xing et al. , 2025 ; Yang et al. , 2025b ) that produce icons or simple SVG drawings typically fail on glyphs. Typography imposes strict geometric and stylistic constraints: long sequences of precise coordinates; watertight topology; consistent stroke logic across characters; and subtle style factors (contrast, terminals, serifs, curvature) that must vary coherently with the target content. Beyond model capacity, practical data issues arise: paired text-glyph examples are scarce ( Google LLC , 2025 ) ; tags in large repositories are noisy and often non-visual ( Envato Pty Ltd , 2025 ) ; and coordinate systems vary across sources. Naively prompting existing LLMs to “write an SVG path for a serif V” often yields broken geometry, mismatched case, or degenerate paths. Table 1 : SVG draw commands used in this work. We serialize each glyph as a single SVG path using only MoveTo , LineTo , Quadratic Bézier , and ClosePath . Uppercase commands use absolute coordinates; lowercase are relative to the current point. Coordinates are quantized to one decimal; other attributes (e.g., “fill”, “stroke”, “transform”) are unused. Command Arguments Description M / m (MoveTo) x x , y y Move the cursor to the end-point ( x , y ) (x,y) without drawing anything. L / l (LineTo) x x , y y Draw a line to the end-point ( x , y ) (x,y) . Q / q (Quadratic Bézier) q x q_{x} , q y q_{y} x x , y y Draw a quadratic Bézier curve with the control point ( q x , q y ) (q_{x},q_{y}) and the end-point ( x , y ) (x,y) . Z / z (ClosePath) ∅ \varnothing Close the path by moving the cursor back to the starting position (ignorable). VecGlypher addresses these challenges and unifies text- and image-referenced vector glyph generation within a single language model ( Fig. ˜ 2 ). Our model is a multimodal decoder that consumes (i) a style description or image exemplars, and (ii) the target character identity, then autoregressively predicts SVG path tokens for the output glyph. The same architecture and decoding procedure handle both input modalities. At inference, generated tokens are de-tokenized into a valid SVG path and rasterized for preview. Achieving reliable glyph drawing with an LLM requires both the right training recipe and typography-aware data engineering. We curate complementary corpora and adopt a two-stage scheme ( Fig. ˜ 3 ): Stage 1 performs large-scale continuation on noisy text-glyph pairs from a 39K-font Envato collection ( Envato Pty Ltd , 2025 ) to teach the model to draw —establishing robust SVG syntax, long-horizon coordinate prediction, and character-conditioned geometry. Stage 2 post-trains on a smaller but higher-quality 2.5K-font Google Fonts set ( Google LLC , 2025 ) with expert descriptors and image exemplars, sharpening the mapping from textual concepts or image exemplers to glyph geometry and enabling unified generation for both modalities. To support stable long-sequence decoding, we design a typography-specific preprocessing pipeline: de-duplicate near-identical fonts; remove malformed or excessively long paths; normalize all glyphs to a consistent coordinate system; serialize each glyph to a canonical SVG path representation; and tokenize commands and coordinates with fixed-precision quantization. These steps lower sequence complexity and reduce error propagation during decoding, turning a general-purpose multimodal LLM into a competent glyph drawer. Fig. ˜ 2 summarizes the contrast with prior paradigms and our resulting pipeline. Compared with dual encoder-decoder systems tailored to image-referenced generation or cascaded image-then-vector diffusion approaches, VecGlypher collapses glyph synthesis into a single autoregressive program that emits vector tokens directly. This yields three practical advantages: (1) no exemplar sheet is required—text alone suffices—while still supporting exemplars when available; (2) avoiding raster intermediates eliminates vectorization artifacts by generating valid SVG in one pass; and (3) the language-modeling formulation scales naturally—larger backbones, more continuation data, and improved tokenization translate into stronger glyph geometry and generalization. Figure 2 : Paradigm comparisons. a) Prior image-referenced pipelines use separate image and vector encoder–decoders and a geometry post-optimizer. b) Diffusion-based approaches cascade image diffusion with a vector decoder. c) VecGlypher unifies both text- and image-referenced conditioning within a single LLM: given a style description or reference glyph images plus a target character, the model autoregressively emits SVG path tokens that detokenize to a valid SVG path. This formulation removes raster intermediates and exemplar-sheet requirements while producing directly editable vectors. A practical workflow is to first generate a few reference glyphs from text descriptions, then bootstrap with those images to synthesize the full font. We evaluate these claims extensively. Both qualitatively and quantitatively, VecGlypher produces cleaner, more stylistically faithful glyphs than specialized image-referenced baselines, and succeeds on text-referenced tasks where state-of-the-art LLMs and vector-graphics LLMs fail to draw at all. Ablations show that (i) model scale is a primary driver of vector fidelity and style consistency, and (ii) large-scale continuation in Stage 1 delivers tangible out-of-distribution gains beyond what limited expert-annotated data alone can offer. Our contributions are summarized as follows: ∙ \bullet Unified formulation. We recast vector glyph generation as language modeling over SVG path tokens and present VecGlypher , a single multimodal LLM that supports both text- and image-referenced conditioning while directly emitting vector code. ∙ \bullet Two-stage training recipe. We curate two complementary datasets (39K noisy fonts; 2.5K expert-annotated fonts) and show that large-scale continuation followed by targeted post-training is key to drawing high-quality glyphs from either modality. ∙ \bullet Empirical validation. Through comprehensive evaluations, we demonstrate substantial improvements over specialized image-referenced methods and show that general SVG-generation LLMs are insufficient for typography, whereas our approach follows textual descriptions and exemplar images with high fidelity. Together, these results indicate that language models, properly trained and paired with typography-aware data engineering, can serve as a unified engine for vector glyph generation. VecGlypher lowers the barrier to font creation, lets users design with words or images, and provides a scalable foundation for future multimodal design tools. Table 2 : Font filtering. Filtering Google Fonts Envato Fonts Total fonts 3,403 82,343 Invalid / Lengthy 2,989 70,248 Duplicated 2,645 65,216 MLLM OCR 2,497 39,497 Table 3 : Font-level dataset statistics. Split Google Fonts Envato Fonts Font Family Font Font Family Font Total 1,117 2,497 23,543 39,497 Train 997 2,243 22,543 37,926 Test 120 254 1,000 1,571 Table 4 : Glyph-level dataset statistics. Split Google Fonts Envato Fonts Original Filtering Original Filtering Total 159,808 157,899 2,527,718 2,495,363 Train 143,552 142,148 2,427,174 2,394,819 Test 16,256 15,751 100,544 100,544 Table 5 : Dataset statistics. Word clouds (left) visualize tag vocabularies for Google Fonts (expert-curated, appearance-focused) versus Envato (noisier, marketing-oriented). The middle plots show the per-font number of tags (Google: concise; Envato: capped at 15). Right: distributions of input token length (tags) and output token length (SVG path tokens), with Envato exhibiting heavier-tailed outputs. These differences motivate our two-stage recipe: large-scale continuation on Envato, then instruction alignment on Google Fonts. 2 Related Works Image-referenced glyph and font generation. Early systems synthesize glyph bitmaps and transfer style across characters from a few exemplar images ( Wang et al. , 2020 ; Reddy et al. , 2021 ; Li and Lian , 2024 ; Yang et al. , 2023 ; He et al. , 2024 ; Hayashi et al. , 2019 ) . While visually compelling, raster pipelines remain decoupled from vectorization, limiting editability and resolution-independent reuse. Vector-native methods instead predict parametric curves directly. ( Lopes et al. , 2019 ) sparked interest in structured, editable vector outputs; subsequent work predicts vector primitives from reference images to reconstruct style-consistent glyphs ( Wang and Lian , 2021 ) , improves contour fidelity and content-style disentanglement ( Wang et al. , 2023 ) , jointly models curve geometry and filled regions ( Liu et al. , 2023b ) , represents glyphs with signed distance fields ( Xia et al. , 2023 ) , and couples diffusion priors with a vector decoder for sparse-exemplar generation ( Thamizharasan et al. , 2024 ) . These specialized architectures are typically trained on moderate-scale corpora (e.g., ( Wang and Lian , 2021 ; Wang et al. , 2023 ) ≈ \approx 8K fonts; ( Thamizharasan et al. , 2024 ) ≈ \approx 1.4K). VecGlypher differs by combining substantially larger supervision (39K+2.5K fonts) with a language-model backbone to unify text or image exemplar-conditioned synthesis and vector decoding, yielding stronger cross-script generalization and directly editable glyph outputs. Text-referenced glyph 