Title: Neural Fields as World Models

Abstract: How does the brain predict physical outcomes while acting in the world? Machine learning world models compress visual input into latent spaces, discarding the spatial structure that characterizes sensory cortex. We propose isomorphic world models: architectures preserving sensory topology so that physics prediction becomes geometric propagation rather than abstract state transition. We implement this using neural fields with motor-gated channels, where activity evolves through local lateral connectivity and motor commands multiplicatively modulate specific populations. Three experiments support this approach: (1) local connectivity is sufficient to learn ballistic physics, with predictions traversing intermediate locations rather than "teleporting"; (2) policies trained entirely in imagination transfer to real physics at nearly twice the rate of latent-space alternatives; and (3) motor-gated channels spontaneously develop body-selective encoding through visuomotor prediction alone. These findings suggest intuitive physics and body schema may share a common origin in spatially structured neural dynamics.

Body: Neural Fields as World Models Introduction Methods Neural Field Architecture Task Environments Training and Evaluation Results Experiment 1: Physics from Lateral Dynamics Experiment 2: Dream Training Transfers Experiment 3: Emergent Body-Selective Encoding Discussion Acknowledgments Neural Fields as World Models Joshua Nunley (joshnunl@iu.edu) Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington Cognitive Science Program, Indiana University, Bloomington Abstract How does the brain predict physical outcomes while acting in the world? Machine learning world models compress visual input into latent spaces, discarding the spatial structure that characterizes sensory cortex. We propose isomorphic world models: architectures preserving sensory topology so that physics prediction becomes geometric propagation rather than abstract state transition. We implement this using neural fields with motor-gated channels, where activity evolves through local lateral connectivity and motor commands multiplicatively modulate specific populations. Three experiments support this approach: (1) local connectivity is sufficient to learn ballistic physics, with predictions traversing intermediate locations rather than ‚Äúteleporting‚Äù; (2) policies trained entirely in imagination transfer to real physics at nearly twice the rate of latent-space alternatives; and (3) motor-gated channels spontaneously develop body-selective encoding through visuomotor prediction alone. These findings suggest intuitive physics and body schema may share a common origin in spatially structured neural dynamics. Keywords: neural fields; world models; intuitive physics; motor control; body schema Introduction A child learning to catch must solve two physics problems at once: where will the ball land, and where will my hand be when I reach? With practice, both predictions become automatic. How does the brain pull this off? Battaglia, Hamrick, and Tenenbaum proposed that humans possess an ‚Äúintuitive physics engine‚Äù (IPE) that runs mental simulations to predict physical outcomes [ 7 ] . The framework accounts for human performance across diverse physical reasoning tasks [ 18 , 26 ] . Several computational frameworks have attempted to model physical intuition. Object-based approaches like Interaction Networks [ 8 ] and the Neural Physics Engine [ 10 ] learn to predict physical dynamics over explicit object graphs. These models capture important structure but operate on symbolic object representations rather than raw visual input, and they do not integrate motor commands. They model physics as an observer, not as an agent. To understand how the brain predicts physics while acting in the world, we need models that integrate action. [ 15 ] proposed that the brain constructs exactly such models: internal emulators that predict the sensory consequences of motor commands. World models from machine learning, which learn these predictions for planning and control, can be seen as computational implementations of this idea [ 16 ] . But these architectures ignore biological constraints. Visual input is compressed through an encoder into a latent vector with no spatial structure, a recurrent model predicts latent state transitions, and finally a decoder reconstructs predictions. In such architectures, a single weight matrix can connect any latent dimension to any other, allowing information to jump discontinuously rather than propagate locally. In the physical world, a ball moves continuously through space, forces act on adjacent objects, and trajectories unfold through spatial neighborhoods. Latent-space world models have no such constraints. Predicted objects can ‚Äúteleport‚Äù across representational space from one timestep to the next. Neuroscience suggests the brain does it differently. Ahuja and colleagues showed that motion-sensitive area MT activates during trajectory prediction even without visual motion [ 1 , 2 ] . Neural patterns during prediction resemble those during actual motion perception, as if physics simulation unfolds within spatially organized visual representations rather than in a separate abstract reasoning system. The brain appears to preserve spatial structure while simulating physics. This leaves a gap: we lack a world model architecture that respects both constraints, spatial structure and action integration. If we want to understand how brains model the world, we need world models that could plausibly exist in brains. We propose that the missing link is isomorphism : world models that preserve the spatial structure of sensory input. The defining constraint is locality : nearby points in the world map to nearby points in the representation, and information propagates through spatial neighbors rather than ‚Äúteleporting‚Äù via global connections. When this constraint is enforced, physics prediction becomes a geometric problem: a ball‚Äôs future is a path through representational space, not an abstract vector transition. To test this hypothesis, we use neural fields , perhaps the simplest implementation of the isomorphic principle. Introduced by Amari [ 3 ] , neural fields are spatially organized recurrent networks where activity evolves through local lateral interactions: each location influences only its spatial neighbors through a connectivity kernel. Neural fields have long served as models of cortical dynamics, capturing phenomena from visual attention to working memory to motor planning. Yet they have not been explored as world models, learning to predict how the world evolves for planning and control. To enable action-conditional prediction, we introduce motor-gated channels : populations whose activity is multiplicatively modulated by motor commands. The mechanism implements gain modulation, a fundamental computational principle in cortex whereby one signal multiplicatively scales neural responses to another [ 24 ] . In posterior parietal cortex, gain fields enable sensorimotor integration by combining visual input with motor signals [ 4 ] . This is precisely the computation our motor-gated channels perform. Figure 1: Neural field world model architecture. Visual input I t I_{t} is added to the hidden state only during the first three timesteps of each sequence; thereafter, the field evolves autonomously through local lateral convolution ( K K ) and recurrence. Motor commands ùê¶ \mathbf{m} multiplicatively gate specific channels, implementing gain modulation. A 1x1 convolution reconstructs the visual prediction I ^ t + 1 \hat{I}_{t+1} . Four lines of evidence support that this architecture implements a biologically plausible world model: 1. Architectural Alignment: The model‚Äôs retinotopic organization and motor-gating mechanism parallel known structures in area MT [ 1 ] and posterior parietal cortex [ 24 ] . 2. Physics from Lateral Dynamics: The constraint of local connectivity proves sufficient to learn ballistic physics, where trajectories emerge from wave-like propagation rather than symbolic rules (Experiment 1). 3. Transferable Motor Control: Policies trained entirely in ‚Äúimagination,‚Äù within the frozen world model, transfer successfully to real physics, suggesting the spatial representation captures actionable structure (Experiment 2). 4. Emergent Body Schema: Motor-gated channels spontaneously develop body-selective encoding through sensorimotor prediction alone, producing the motor-linked self-representation characteristic of body schema [ 13 ] (Experiment 3). Methods Neural Field Architecture The neural field instantiates the key constraint motivating our approach: information propagates through spatial neighbors, never teleporting across the representation. At each timestep, the field state ùê° ‚àà ‚Ñù C √ó H √ó W \mathbf{h}\in\mathbb{R}^{C\times H\times W} updates through three influences: decay of current activity, lateral input from neighboring locations, and visual input from the environment. A learned convolutional kernel K K ( 7 √ó 7 7\times 7 ) implements lateral connectivity, ensuring that predicted motion must traverse intermediate positions just as objects traverse intermediate locations in physical space. Formally, the dynamics follow Amari‚Äôs neural field equations [ 3 ] : ùê° t + 1 = ùê° t + Œî ‚Äã t œÑ ‚Äã ( ‚àí ùê° t + K ‚àó ReLU ‚Äã ( ùê° t ) + W in ‚àó ùêà t ) \mathbf{h}_{t+1}=\mathbf{h}_{t}+\frac{\Delta t}{\tau}\left(-\mathbf{h}_{t}+K*\text{ReLU}(\mathbf{h}_{t})+W_{\text{in}}*\mathbf{I}_{t}\right) (1) Visual predictions emerge through linear reconstruction: ùêà ^ t = W out ‚àó ùê° t \hat{\mathbf{I}}_{t}=W_{\text{out}}*\mathbf{h}_{t} . To integrate motor commands, we designate the first M M channels as motor-gated. After each dynamics update, these channels are multiplicatively modulated by motor signals: ùê° t + 1 ( i ) = m i ‚ãÖ ùê° ~ t + 1 ( i ) for ‚Äã i ‚àà { 1 , ‚Ä¶ , M } \mathbf{h}_{t+1}^{(i)}=m_{i}\cdot\tilde{\mathbf{h}}_{t+1}^{(i)}\quad\text{for }i\in\{1,\ldots,M\} (2) This implements gain modulation, the same computational principle by which posterior parietal cortex combines visual and motor signals [ 24 , 4 ] . Biological plausibility. We do not claim the neural field is a complete model of cortex. Rather, it respects two cortical constraints that standard world model architectures (VAE-LSTMs, transformers, diffusion models) violate: retinotopic organization maintains spatial correspondence with visual input [ 27 ] , and local lateral connectivity limits interactions to spatial neighbors. We use ReLU as a threshold-linear approximation to spike-rate rectification, and convolutional kernels to abstract local connectivity patterns. Regarding learning: we use backpropagation, though recent work suggests cortical circuits may implement functionally similar credit assignment [ 20 ] . Our claim concerns the computational architecture, not the specific learning mechanism. Task Environments Ballistic trajectory (Experiment 1). A ball moves under gravity in a 32 √ó 32 32\times 32 visual field, with random initial position and velocity. The model observes the first 3 frames, then predicts the remainder without visual input. Architecture: 16 channels (no motor gating). Musculoskeletal arm (Experiments 2‚Äì3). A planar double-pendulum arm operates in a 120 √ó 45 120\times 45 visual field with four motor commands following the Equilibrium-Point Hypothesis [ 11 ] : co-contraction (C) commands control joint stiffness, reciprocal (R) commands control movement direction. A ball falls from a random horizontal position for catching. Architecture: 32 channels (4 motor-gated). Training and Evaluation World models are trained with mean squared prediction loss (Adam optimizer, 10,000 epochs). For dream training (Experiment 2), we freeze the world model and train a policy network by backpropagating through the differentiable dynamics. A separately trained catch predictor provides the learning signal; the policy maximizes predicted catch probability with gradients flowing through the frozen world model. The trained policy deploys to real physics without fine-tuning. Catch rate measures successful interceptions over 100 episodes. For body schema analysis (Experiment 3), we compute a selectivity index comparing motor-gated channel activity over arm versus ball regions, normalized by reconstruction activity: Selectivity = Motor arm / Motor ball Recon arm / Recon ball \text{Selectivity}=\frac{\text{Motor}_{\text{arm}}/\text{Motor}_{\text{ball}}}{\text{Recon}_{\text{arm}}/\text{Recon}_{\text{ball}}} Values greater than 1 indicate body-selective representation. Baseline. We compare against a VAE-LSTM inspired by [ 16 ] : a convolutional VAE compresses observations to a 32-dimensional latent space, an LSTM predicts latent dynamics, and a decoder reconstructs predictions. Following [ 16 ] , training proceeds in two stages (VAE first for 10,000 epochs, then frozen VAE plus LSTM for 10,000 epochs) because gradients through the decoder destabilize joint training. The neural field requires no staged training and uses 17‚Äì67 √ó \times fewer parameters (13K vs 850K for ballistic; 50K vs 1.7M for arm), largely because the VAE-LSTM requires dense layers connecting flattened features to latent space. Results Experiment 1: Physics from Lateral Dynamics Figure 2: Trajectory prediction through internal dynamics. Each column shows a different ballistic trajectory (50‚Äì59 timesteps). Both models observe only the first three frames before predicting the remainder without visual input. The neural field (green) maintains smooth parabolic arcs closely tracking ground truth (gray dotted), while the VAE-LSTM (orange) exhibits erratic oscillations. Figure 2 shows ballistic prediction: after observing a ball for three frames, activity in the neural field continues along the parabolic arc even without visual input. During observation, a localized bump tracks the ball; remove the input, and the bump keeps moving, following learned dynamics that approximate ballistic motion. Across 10 seeds, the neural field achieves median prediction loss of 9.33 √ó 10 ‚àí 4 9.33\times 10^{-4} (IQR: [ 0.000895 0.000895 , 0.000988 0.000988 ]), compared to 3.94 √ó 10 ‚àí 3 3.94\times 10^{-3} for VAE-LSTM (p 0.001). Beyond aggregate loss, VAE-LSTMs exhibit a failure mode that neural fields avoid. We measured frame-to-frame displacement of predicted centroids during blind rollouts. The neural field‚Äôs maximum displacement was 2.06 pixels, with 0.0% of sequences showing ‚Äúteleportation‚Äù (jumps 3.0 pixels). VAE-LSTM showed 21.97 pixels maximum (10.7 √ó \times larger) and 15.4% teleportation (p 0.001). Local connectivity bounds how far predictions can jump in a single timestep; latent-space models lack this constraint. Experiment 2: Dream Training Transfers An important test for world models is whether policies trained in imagination transfer to reality. We freeze the trained neural field world model, then train a policy network to catch falling balls using only the model‚Äôs prediction of the visual field. The policy receives the neural field reconstruction as input and outputs motor commands. Training proceeds entirely within the world model: the model generates predicted observations, the policy generates actions, and a catch predictor (trained on real physics) scores each trajectory, with gradients flowing through the differentiable world model to the policy. No real-environment interaction occurs during policy training. Figure 3: Visuomotor prediction in the arm catching task. Both models receive motor commands throughout, but visual input only during the first three frames (Obs). Ground truth shown as gray dots. The vertical dashed line marks the transition to blind prediction. Figure 3 shows the arm task: a double pendulum controlled by muscle-like actuators must catch a falling ball. The neural field receives motor commands alongside visual input during observation, then predicts the visual consequences of continued motor activity during the blind phase. Policies trained within the neural field achieve 81.5% catch rate (IQ