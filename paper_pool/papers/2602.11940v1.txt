Title: Temporally Unified Adversarial Perturbations for Time Series Forecasting

Abstract: While deep learning models have achieved remarkable success in time series forecasting, their vulnerability to adversarial examples remains a critical security concern. However, existing attack methods in the forecasting field typically ignore the temporal consistency inherent in time series data, leading to divergent and contradictory perturbation values for the same timestamp across overlapping samples. This temporally inconsistent perturbations problem renders adversarial attacks impractical for real-world data manipulation. To address this, we introduce Temporally Unified Adversarial Perturbations (TUAPs), which enforce a temporal unification constraint to ensure identical perturbations for each timestamp across all overlapping samples. Moreover, we propose a novel Timestamp-wise Gradient Accumulation Method (TGAM) that provides a modular and efficient approach to effectively generate TUAPs by aggregating local gradient information from overlapping samples. By integrating TGAM with momentum-based attack algorithms, we ensure strict temporal consistency while fully utilizing series-level gradient information to explore the adversarial perturbation space. Comprehensive experiments on three benchmark datasets and four representative state-of-the-art models demonstrate that our proposed method significantly outperforms baselines in both white-box and black-box transfer attack scenarios under TUAP constraints. Moreover, our method also exhibits superior transfer attack performance even without TUAP constraints, demonstrating its effectiveness and superiority in generating adversarial perturbations for time series forecasting models.

Body: Temporally Unified Adversarial Perturbations for Time Series Forecasting 1 Introduction 2 Related Work 2.1 Preliminaries 2.2 Foundational Adversarial Attack Methods 2.3 Adversarial Attacks for Time Series Forecasting 3 Methodology 3.1 Motivation 3.2 Temporally Unified Adversarial Perturbation 3.3 Adversarial Perturbation Generation 3.4 Implementation of Attacking Algorithm 4 Experiment 4.1 Experimental Setup Datasets. Models. Baselines. Attack Settings. 4.2 White-box Attack Results 4.3 Transfer Attack Results 4.4 Sensitivity Analysis 4.5 Visual Analysis 4.6 Comparison in Temporal Inconsistent Settings 5 Conclusion Temporally Unified Adversarial Perturbations for Time Series Forecasting Ruixian Su School of Management Huazhong University of Science and Technology ruixiansu@hust.edu.cn Yukun Bao School of Management Huazhong University of Science and Technology yukunbao@hust.edu.cn Xinze Zhang School of Computer Science and Technology Huazhong University of Science and Technology xinze@hust.edu.cn Corresponding author: Xinze Zhang. Abstract While deep learning models have achieved remarkable success in time series forecasting, their vulnerability to adversarial examples remains a critical security concern. However, existing attack methods in the forecasting field typically ignore the temporal consistency inherent in time series data, leading to divergent and contradictory perturbation values for the same timestamp across overlapping samples. This temporally inconsistent perturbations problem renders adversarial attacks impractical for real-world data manipulation. To address this, we introduce Temporally Unified Adversarial Perturbations (TUAPs), which enforce a temporal unification constraint to ensure identical perturbations for each timestamp across all overlapping samples. Moreover, we propose a novel Timestamp-wise Gradient Accumulation Method (TGAM) that provides a modular and efficient approach to effectively generate TUAPs by aggregating local gradient information from overlapping samples. By integrating TGAM with momentum-based attack algorithms, we ensure strict temporal consistency while fully utilizing series-level gradient information to explore the adversarial perturbation space. Comprehensive experiments on three benchmark datasets and four representative state-of-the-art models demonstrate that our proposed method significantly outperforms baselines in both white-box and black-box transfer attack scenarios under TUAP constraints. Moreover, our method also exhibits superior transfer attack performance even without TUAP constraints, demonstrating its effectiveness and superiority in generating adversarial perturbations for time series forecasting models. K eywords Time Series Forecasting, Adversarial Attack, Temporally Unified Adversarial Perturbation, Timestamp-wise Gradient Accumulation Method 1 Introduction Deep-learning-based time series forecasting has been widely deployed due to its superior predictive performance, serving as a pivotal tool for operations and risk management across critical sectors, such as smart grids [ 1 ] , manufacturing [ 26 ] , and finance [ 17 ] . Despite these advances, recent studies have revealed that deep learning models are vulnerable to adversarial examples, i.e. , inputs with carefully crafted perturbations that lead to incorrect predictions [ 20 ] . This particularly indicates the adversarial vulnerability in time series forecasting applications, where malicious perturbations could mislead forecasting systems into making erroneous decisions with catastrophic consequences. Consequently, investigating the reliability and robustness of time series forecasting models under adversarial attacks has garnered considerable attention. While adversarial attacks in vision and language domains have been extensively studied, attacks in the forecasting field remain limited. Early attempts at adversarial attacks on time series forecasting directly adapted image-based attack methods, such as the Fast Gradient Sign Method (FGSM) [ 6 ] , treating time series as one-dimensional images [ 15 , 7 ] . However, such adaptations neglect the unique temporal dependencies in time series [ 2 ] . More recent works have begun to tailor adversarial attack strategies specifically for time series forecasting, such as the importance measuring method AAIM [ 24 ] , the temporal similarity constraint method TCA [ 19 ] , and the attack direction selection method AAJM [ 8 ] , which have significantly enhanced the effectiveness of adversarial attacks in the time series forecasting domain. Despite their efficacy, existing methods overlook the auto-regressive sliding-window characteristic of time series forecasting, which makes forecasting tasks inherently distinct from other tasks. This mechanism implies that a historical value at a specific timestamp is repeatedly sampled and observed within multiple input samples. Since conventional attack frameworks optimize perturbations for each sample in isolation, they inevitably generate divergent, often contradictory, perturbation values for the same timestamp across different samples, leading to the "temporally inconsistent perturbations" problem. This lack of temporal consistency renders such adversarial examples impractical for real-world data manipulation, thereby hindering a realistic evaluation of the adversarial robustness of time series forecasting systems. To address these limitations, we propose a novel and practical concept of adversarial perturbations, namely Temporally Unified Adversarial Perturbations (TUAPs), which significantly degrade the accuracy of state-of-the-art forecasting models while explicitly enforcing a temporal unification constraint that ensures the perturbation at each specific timestamp is shared across all overlapping samples. Since TUAPs impose a more stringent constraint on the perturbation space, generating effective TUAPs is more challenging than crafting traditional perturbations. To effectively generate TUAPs, we further propose a modular and efficient Timestamp-wise Gradient Accumulation Method (TGAM), by aggregating local gradient information from overlapping samples to optimize perturbations under the temporal consistency constraint. Through integrating TGAM with momentum-based attack algorithms, we demonstrate that our proposed method can be easily incorporated into existing attack frameworks to enhance their effectiveness for time series forecasting. Our main contributions are summarized as follows: â€¢ We pioneer the investigation of Temporally Unified Adversarial Perturbations (TUAPs) for time series forecasting, demonstrating that state-of-the-art forecasting models can be effectively attacked across all overlapping samples using temporally unified perturbations that maintain practical feasibility. â€¢ We propose the Timestamp-wise Gradient Accumulation Method (TGAM) to effectively generate TUAPs, which efficiently aggregates gradient information from overlapping samples to optimize perturbations under the temporal consistency constraint. â€¢ We conduct extensive experiments demonstrating that our proposed method significantly outperforms all baselines in both white-box and black-box attack scenarios under TUAP constraints, and even exceeds unconstrained baselines in transfer attack scenarios, demonstrating its effectiveness and superiority in attacking time series forecasting models. The remainder of this paper is organized as follows. Section 2 provides preliminaries on time series forecasting and reviews related work on adversarial attacks. Section 3 details the motivation of this work, the definition of TUAPs, and the implementation of our proposed TGAM. Section 4 presents the experimental setup, results, and analysis. Finally, Section 5 concludes the paper and discusses future research. 2 Related Work 2.1 Preliminaries Figure 1: Illustration of the preliminaries of time series forecasting and adversarial attack on time series forecasting. As shown in Fig. Ëœ 1 , in a general time series forecasting task, the objective is to predict a sequence of future observations based on a given sequence of historical data. Typically, consider a raw time series ğ’± = { ğ’— 1 , ğ’— 2 , â€¦ , ğ’— t , â€¦ , ğ’— T } âˆˆ â„ T Ã— D \mathcal{V}=\{\bm{v}_{1},\bm{v}_{2},\dots,\bm{v}_{t},\dots,\bm{v}_{T}\}\in\mathbb{R}^{T\times D} , where T T is the total length of the time series, ğ’— t âˆˆ â„ D , ğ’— t = [ v t 1 , v t 2 , â€¦ , v t D ] \bm{v}_{t}\in\mathbb{R}^{D},\bm{v}_{t}=[v_{t}^{1},v_{t}^{2},\ldots,v_{t}^{D}] denotes the observation vector at time t t , and D D is the dimension (number of variables) of each observation. Forecasting models employ a sliding-window mechanism to consecutively sample ğ’± \mathcal{V} without strides 1 1 1 We provide a dynamical visualization of what this non-stride sampling does in the link: https://github.com/Simonnop/timeË™seriesË™sampling/blob/main/README.md to construct a time series dataset ğ’Ÿ \mathcal{D} that consists of N N input-target pairs { ( ğ’™ n , ğ’š n ) } n = 1 N \{(\bm{x}_{n},\bm{y}_{n})\}_{n=1}^{N} . Specifically, let L L denote the input lookback window length and H H denote the forecasting horizon. The input ğ’™ n âˆˆ â„ L Ã— D \bm{x}_{n}\in\mathbb{R}^{L\times D} and target ğ’š n âˆˆ â„ H Ã— D \bm{y}_{n}\in\mathbb{R}^{H\times D} are sampled as ğ’™ n = [ ğ’— n , ğ’— n + 1 , â€¦ , ğ’— n + L âˆ’ 1 ] \bm{x}_{n}=[\bm{v}_{n},\bm{v}_{n+1},\ldots,\bm{v}_{n+L-1}] and ğ’š n = [ ğ’— n + L , ğ’— n + L + 1 , â€¦ , ğ’— n + L + H âˆ’ 1 ] \bm{y}_{n}=[\bm{v}_{n+L},\bm{v}_{n+L+1},\ldots,\bm{v}_{n+L+H-1}] , respectively. For brevity, let ğ’— n : n + L âˆ’ 1 = [ ğ’— n , ğ’— n + 1 , â€¦ , ğ’— n + L âˆ’ 1 ] \bm{v}_{n:n+L-1}=[\bm{v}_{n},\bm{v}_{n+1},\ldots,\bm{v}_{n+L-1}] denote the time series values from timestamp n n to timestamp n + L âˆ’ 1 n+L-1 , so that ğ’™ n = ğ’— n : n + L âˆ’ 1 \bm{x}_{n}=\bm{v}_{n:n+L-1} , ğ’š n = ğ’— n + L : n + L + H âˆ’ 1 \bm{y}_{n}=\bm{v}_{n+L:n+L+H-1} , and N = T âˆ’ L âˆ’ H + 1 N=T-L-H+1 . Deep forecasting models learn a mapping function f Î¸ : ğ’³ â†’ ğ’´ f_{\theta}:\mathcal{X}\to\mathcal{Y} , where ğ’³ âŠ† â„ L Ã— D \mathcal{X}\subseteq\mathbb{R}^{L\times D} and ğ’´ âŠ† â„ H Ã— D \mathcal{Y}\subseteq\mathbb{R}^{H\times D} are the input and target spaces, respectively. The objective is to minimize a loss function â„’ â€‹ ( â‹… , â‹… ) \mathcal{L}(\cdot,\cdot) ( e.g. , mean squared error [ 23 , 13 ] ) between the prediction ğ’š ^ n = f Î¸ â€‹ ( ğ’™ n ) \hat{\bm{y}}_{n}=f_{\theta}(\bm{x}_{n}) and the ground truth ğ’š n {\bm{y}}_{n} with the optimal parameters Î¸ âˆ— \theta^{*} : Î¸ âˆ— = argmin ğœƒ â€‹ â„’ â€‹ ( ğ’š ^ n , ğ’š n ) . \theta^{*}=\underset{\theta}{\operatorname{argmin}}\,\mathcal{L}(\hat{\bm{y}}_{n},\bm{y}_{n}). (1) In contrast, adversarial attacks aim to find an adversarial example ğ’™ n â€² = ğ’™ n + ğœ¹ n {\bm{x}}^{\prime}_{n}=\bm{x}_{n}+\bm{\delta}_{n} within a small neighborhood of the original input ğ’™ n {\bm{x}}_{n} that causes erroneous predictions, where ğœ¹ n \bm{\delta}_{n} is the adversarial perturbation. For each sample ğ’™ n \bm{x}_{n} , the objective is to maximize the loss function â„’ â€‹ ( â‹… , â‹… ) \mathcal{L}(\cdot,\cdot) between the prediction ğ’š ^ n â€² = f Î¸ â€‹ ( ğ’™ n â€² ) \hat{\bm{y}}^{\prime}_{n}=f_{\theta}({\bm{x}}^{\prime}_{n}) and the ground truth ğ’š n \bm{y}_{n} with the optimal perturbation ğœ¹ n âˆ— {\bm{\delta}}_{n}^{*} : ğœ¹ n âˆ— = argmax ğœ¹ n â€‹ â„’ â€‹ ( ğ’š ^ n â€² , ğ’š n ) s.t. â€– ğœ¹ n â€– p â‰¤ Ïµ , {\bm{\delta}}_{n}^{*}=\underset{{\bm{\delta}}_{n}}{\operatorname{argmax}}\,\mathcal{L}\left(\hat{\bm{y}}^{\prime}_{n},\bm{y}_{n}\right)\quad\text{s.t.}\quad\|{\bm{\delta}}_{n}\|_{p}\leq\epsilon, (2) where â€– ğœ¹ n â€– p â‰¤ Ïµ \|\bm{\delta}_{n}\|_{p}\leq\epsilon constrains the perturbation magnitude, i.e. , the L p L_{p} norm of the perturbation ğœ¹ n \bm{\delta}_{n} must be less than or equal to a threshold Ïµ \epsilon , with L âˆ L_{\infty} being the most commonly adopted norm [ 3 , 16 ] . 2.2 Foundational Adversarial Attack Methods Adversarial attacks serve as an important tool for assessing the adversarial robustness of deep learning models. Since Szegedy et al. [ 20 ] first identified the vulnerability of Deep Neural Networks (DNNs), research in this field has flourished, primarily within the computer vision domain. As a foundational work, Goodfellow et al. [ 6 ] propose the Fast Gradient Sign Method (FGSM), which generates adversarial perturbations via a single-step update along the direction of the loss gradient: ğœ¹ n = Ïµ â‹… sign â¡ ( âˆ‡ ğ’™ n â„’ â€‹ ( ğ’š ^ n , ğ’š n ) ) = { Ïµ , if â€‹ âˆ‡ ğ’™ n â„’ â€‹ ( ğ’š ^ n , ğ’š n ) 0 0 , if â€‹ âˆ‡ ğ’™ n â„’ â€‹ ( ğ’š ^ n , ğ’š n ) = 0 âˆ’ Ïµ , if â€‹ âˆ‡ ğ’™ n â„’ â€‹ ( ğ’š ^ n , ğ’š n ) 0 , \bm{\delta}_{n}=\epsilon\cdot\operatorname{sign}(\nabla_{\bm{x}_{n}}\mathcal{L}(\hat{\bm{y}}_{n},\bm{y}_{n}))=\begin{cases}\epsilon, \text{if }\nabla_{\bm{x}_{n}}\mathcal{L}(\hat{\bm{y}}_{n},\bm{y}_{n}) 0\\ 0, \text{if }\nabla_{\bm{x}_{n}}\mathcal{L}(\hat{\bm{y}}_{n},\bm{y}_{n})=0\\ -\epsilon, \text{if }\nabla_{\bm{x}_{n}}\mathcal{L}(\hat{\bm{y}}_{n},\bm{y}_{n}) 0\end{cases}, (3) where sign â¡ ( â‹… ) \operatorname{sign}(\cdot) is the sign function, and âˆ‡ ğ’™ n â„’ â€‹ ( ğ’š ^ n , ğ’š n ) \nabla_{\bm{x}_{n}}\mathcal{L}(\hat{\bm{y}}_{n},\bm{y}_{n}) is the gradient of the loss â„’ â€‹ ( ğ’š ^ n , ğ’š n ) \mathcal{L}(\hat{\bm{y}}_{n},\bm{y}_{n}) with respect to ğ’™ n \bm{x}_{n} . While efficient, this single-step attack may be limited in effectiveness on complex model architectures due to its simplistic optimization of adversarial perturbations. To overcome the limitations of FGSM, Kurakin et al. [ 9 ] propose an iterative variant known as the Basic Iterative Method (BIM). Let k âˆˆ { 0 , 1 , â€¦ , K âˆ’ 1 } k\in\{0,1,\ldots,K-1\} denote the iteration index and K K denote the maximum number of iterations. ğ’™ n â€² , k \bm{x}^{\prime,k}_{n} and ğœ¹ n k \bm{\delta}^{k}_{n} denote the adversarial example and adversarial perturbation at the k k -th iteration, BIM can be formulated as: ğ’™ n â€² , k + 1 \displaystyle\bm{x}^{\prime,k+1}_{n} = ğ’™ n + ğœ¹ n k + 1 , \displaystyle=\bm{x}_{n}+\bm{\delta}_{n}^{k+1}, (4) ğœ¹ n k + 1 \displaystyle\bm{\delta}^{k+1}_{n} = clip â¡ ( ğœ¹ ~ n k + 1 , Ïµ ) = { Ïµ , if â€‹ ğœ¹ ~ n k + 1 Ïµ , âˆ’ Ïµ , if â€‹ ğœ¹ ~ n k + 1 âˆ’ Ïµ , ğœ¹ ~ n k + 1 , otherwise , \displaystyle={\operatorname{clip}(\tilde{\bm{\delta}}_{n}^{k+1},\epsilon)}=\begin{cases}\epsilon, \text{if }\tilde{\bm{\delta}}_{n}^{k+1} \epsilon,\\ -\epsilon, \text{if }\tilde{\bm{\delta}}_{n}^{k+1} -\epsilon,\\ \tilde{\bm{\delta}}_{n}^{k+1}, \text{otherwise},\end{cases} (5) ğœ¹ ~ n k + 1 \displaystyle\tilde{\bm{\delta}}_{n}^{k+1} = ğœ¹ n k + Î± â‹… sign â¡ ( âˆ‡ ğ’™ n â€² , k â„’ â€‹ ( f Î¸ â€‹ ( ğ’™ n â€² , k ) , ğ’š n ) ) , \displaystyle=\bm{\delta}_{n}^{k}+\alpha\cdot\operatorname{sign}(\nabla_{\bm{x}^{\prime,k}_{n}}\mathcal{L}(f_{\theta}(\bm{x}^{\prime,k}_{n}),\bm{y}_{n})), (6) where ğ’™ n â€² , 0 = ğ’™ n \bm{x}^{\prime,0}_{n}=\bm{x}_{n} , ğœ¹ n 0 = ğŸ \bm{\delta}^{0}_{n}=\bm{0} , and Î± \alpha is the step size with Î± Ïµ \alpha \epsilon .. This iterative approach allows for a more thorough exploration of the adversarial space. Facing the issue of getting trapped in local extrema during optimization, Madry et al. [ 14 ] propose Projected Gradient Descent (PGD), which extends BIM by intr