Title: DM4CT: Benchmarking Diffusion Models for Computed Tomography Reconstruction

Abstract: Diffusion models have recently emerged as powerful priors for solving inverse problems. While computed tomography (CT) is theoretically a linear inverse problem, it poses many practical challenges. These include correlated noise, artifact structures, reliance on system geometry, and misaligned value ranges, which make the direct application of diffusion models more difficult than in domains like natural image generation. To systematically evaluate how diffusion models perform in this context and compare them with established reconstruction methods, we introduce DM4CT, a comprehensive benchmark for CT reconstruction. DM4CT includes datasets from both medical and industrial domains with sparse-view and noisy configurations. To explore the challenges of deploying diffusion models in practice, we additionally acquire a high-resolution CT dataset at a high-energy synchrotron facility and evaluate all methods under real experimental conditions. We benchmark ten recent diffusion-based methods alongside seven strong baselines, including model-based, unsupervised, and supervised approaches. Our analysis provides detailed insights into the behavior, strengths, and limitations of diffusion models for CT reconstruction. The real-world dataset is publicly available at zenodo.org/records/15420527, and the codebase is open-sourced at github.com/DM4CT/DM4CT.

Body: DM4CT: Benchmarking Diffusion Models for Computed Tomography Reconstruction 1 Introduction 2 Preliminaries 2.1 Computed Tomography 2.2 Diffusion Models 3 DM4CT 3.1 Diffusion Models for CT Reconstruction 3.2 Datasets and Configurations 3.3 Implementation and Comparison Methods 4 Results and Discussions 5 Conclusion A Appendix A.1 Limitations A.2 Broader Impact A.3 Use of Large Language Models A.4 Range Null Space Decomposition A.5 Diffusion Models for CT Reconstruction A.6 Experimental Setups for Medical and Industrial Datasets A.7 Real-World Synchrotron CT Dataset A.8 Towards value range misalignment: A Small Case Study A.9 Sensitivity of DDS to Noise Model A.10 Segmentation as a Downstream Task A.11 Fine Tuning Existing Natural Image Encoders A.12 Abalation for Data Consistency Optimization A.13 Comparison between Training Stages on Reconstruction Performance A.14 Additional Results A.15 Implementation Details A.16 Training Details A.17 Hyperparameter Selection A.18 Differentiable CT Forward Operator DM4CT: Benchmarking Diffusion Models for Computed Tomography Reconstruction Jiayang Shi 1,2 , DaniÃ«l M. Pelt 1 , K. Joost Batenburg 1 1 LIACS, Leiden University 2 Centrum Wiskunde en Informatica Abstract Diffusion models have recently emerged as powerful priors for solving inverse problems. While computed tomography (CT) is theoretically a linear inverse problem, it poses many practical challenges. These include correlated noise, artifact structures, reliance on system geometry, and misaligned value ranges, which make the direct application of diffusion models more difficult than in domains like natural image generation. To systematically evaluate how diffusion models perform in this context and compare them with established reconstruction methods, we introduce DM4CT, a comprehensive benchmark for CT reconstruction . DM4CT includes datasets from both medical and industrial domains with sparse-view and noisy configurations. To explore the challenges of deploying diffusion models in practice, we additionally acquire a high-resolution CT dataset at a high-energy synchrotron facility and evaluate all methods under real experimental conditions. We benchmark ten recent diffusion-based methods alongside seven strong baselines, including model-based, unsupervised, and supervised approaches. Our analysis provides detailed insights into the behavior, strengths, and limitations of diffusion models for CT reconstruction. The real-world dataset is publicly available at zenodo.org/records/15420527 , and the codebase is open-sourced at github.com/DM4CT/DM4CT . 1 Introduction Computed tomography (CT) is a typical example of an inverse problem, where the goal is to reconstruct an unknown object from indirect measurements (Sidky et al., 2020 ; Courdurier et al., 2008 ; Purisha et al., 2019 ) . Techniques developed for CT reconstruction often extend to other inverse problems across various imaging applications (Clement et al., 2005 ; Mistretta et al., 2006 ; Dines Lytle, 2005 ; Ladas Devaney, 1993 ) . In many cases, the measurements are sparse or noisy, making the reconstruction problem ill-posed. This leads to ambiguity, as multiple solutions may fit the measurements equally well. To resolve this, prior knowledge is typically incorporated. Approaches to utilize priors range from heuristic regularizers, such as total variation (TV) (Sidky Pan, 2008 ; Goris et al., 2012 ) , to learned priors via supervised deep learning (Jin et al., 2017 ) . Recently, diffusion models have emerged as powerful generative models, achieving remarkable success in text and image generation (Wu et al., 2023c ; Li et al., 2022 ; Nichol et al., 2021 ; Ho et al., 2022 ) . Motivated by their expressive modeling capacity, many works have proposed to use diffusion models as learned priors for inverse problems, showing promising results across a variety of domains (Chung et al., 2023 ; Song et al., 2024 ; Zirvi et al., 2025 ) . Theoretically, CT reconstruction is a linear inverse problem and thus should benefit from these advances. However, practical CT imaging introduces many additional challenges. Factors such as complex noise characteristics, nonlinear preprocessing steps like log transformation, and various artifacts result in real-world CT pipelines deviating substantially from the idealized linear model (Hendriksen et al., 2020 ) . Therefore, a comprehensive and realistic benchmark is essential to rigorously evaluate diffusion models for CT reconstruction and to compare them against other established CT reconstruction approaches. In this work, we introduce DM4CT, a benchmark designed to evaluate diffusion-based methods for CT reconstruction. We compare diffusion models with each other and against a range of strong, established baselines. As part of DM4CT, we also propose a unified taxonomy that organizes different diffusion approaches based on their strategies for incorporating data consistency and prior knowledge (summarized in Table 1 ). The benchmark includes both medical and industrial CT datasets with controlled levels of noise and artifacts for objective, systematic comparison. In addition, we acquire a real-world dataset by scanning two rock samples at a synchrotron facility, allowing us to examine the limitations of deploying diffusion methods in practice under realistic conditions. An overview of our framework is illustrated in Figure 1 . Our contributions: 1) We present DM4CT, the first systematic benchmark of diffusion models for CT reconstruction; 2) We acquire and release a high-energy synchrotron CT dataset, offering a rare, well-suited resource for benchmarking under realistic conditions; 3) We propose a unified taxonomy of diffusion methods based on their strategies for data consistency and prior knowledge (Table 1 ); 4) We implement all benchmarked methods in the widely adopted diffusers 1 1 1 https://github.com/huggingface/diffusers framework and open-source the codebase; 5) We perform extensive experiments providing practical insights into the strengths, limitations, and deployment challenges of diffusion models in CT. We emphasize that our goal is not to propose a new reconstruction algorithm, but to provide the first systematic benchmark for diffusion models in CT. Figure 1: Overview of the DM4CT benchmark. (a) The reconstruction pipeline, where representative diffusion and baseline methods are applied to measured sinograms using the same forward model. (b) The datasets used in the benchmark, including two simulated CT datasets (medical and industrial) and one real-world dataset acquired at a synchrotron facility. (c) The five simulation configurations used to evaluate robustness to limited views, noise, and ring artifacts. Two example FBP reconstructions under noise and ring artifact conditions are shown. (d) The evaluation metrics, including both qualitative (visual) and quantitative (image quality and computational efficiency) criteria. 2 Preliminaries 2.1 Computed Tomography CT aims to recover an unknown object ğ’™ âˆˆ â„ m \bm{x}\in\mathbb{R}^{m} from a set of projection measurements ğ’š âˆˆ â„ n \bm{y}\in\mathbb{R}^{n} . The measurement process can be mathematically modeled as a linear system ğ’š = ğ‘¨ â€‹ ğ’™ , \bm{y}=\bm{A}\bm{x}, (1) where ğ‘¨ âˆˆ â„ n Ã— m \bm{A}\in\mathbb{R}^{n\times m} is the system matrix determined by the acquisition geometry. In practical settings, the measurements can be sparse (i.e., n m n m ), leading to an underdetermined and ill-posed inverse problem. Furthermore, the measurements acquired during scanning are typically corrupted by noise. We denote the actual observed measurements as ğ’š ~ âˆˆ â„ n \widetilde{\bm{y}}\in{\mathbb{R}}^{n} . The discrepancy between the ideal and observed measurements describes the measurement noise Ïµ = ğ’š ~ âˆ’ ğ’š \bm{\epsilon}=\widetilde{\bm{y}}-\bm{y} . The combination of sparsity and measurement noise poses significant challenges for accurate image reconstruction in CT. To address such challenges, prior knowledge is necessitated for the reconstruction. Classical methods often utilize heuristic priors such as Total Variation (TV) regularization (Sidky Pan, 2008 ; Goris et al., 2012 ; Liu et al., 2013 ; Kazantsev et al., 2018 ) , which assume image smoothness but lack domain-specific adaptability. Recent approaches leverage data-driven priors by training deep neural networks on paired sparse- and dense-view reconstruction images (Jin et al., 2017 ; Chen et al., 2017 ; Pelt et al., 2018 ; Zhang et al., 2021 ) , capturing more expressive and task-specific features. Alternatively, implicit priors such as Deep Image Prior (DIP) (Ulyanov et al., 2018 ; Baguer et al., 2020 ; Barbano et al., 2022 ) and Implicit Neural Representations (INRs) (Sitzmann et al., 2020 ; Shen et al., 2022 ; Wu et al., 2023b ) regularize reconstruction through the neural network itself. 2.2 Diffusion Models We briefly review the two types of diffusion models that are used as backbones in this work. Pixel Diffusion Models. We consider Pixel-space Diffusion Probabilistic Models (DDPMs) (Ho et al., 2020 ; Nichol Dhariwal, 2021 ) and view the forward diffusion and backward denoising processes as Stochastic Differential Equations (SDEs) (Song et al., 2020 ) . In the forward process, Gaussian noise is gradually added to data ğ’™ 0 âˆ¼ p d â€‹ a â€‹ t â€‹ a \bm{x}_{0}\sim p_{data} such that, at a sufficiently large time T T , the perturbed variable ğ’™ T \bm{x}_{T} approximates a Gaussian distribution ğ’™ T âˆ¼ ğ’© â€‹ ( 0 , ğ‘° ) \bm{x}_{T}\sim\mathcal{N}(0,\bm{I}) . This process can be described by the Variance-Preserving Stochastic Differential Equation (VP-SDE) (Song et al., 2020 ) : d â€‹ ğ’™ = âˆ’ Î² t 2 â€‹ ğ’™ + Î² t â€‹ d â€‹ ğ’˜ , d\bm{x}=-\frac{\beta_{t}}{2}\bm{x}+\sqrt{\beta_{t}}d\bm{w}, (2) where the Î² t \beta_{t} is a time-dependent noise schedule, and d â€‹ ğ’˜ d\bm{w} denotes the standard Wiener process. The backward denoising process attempts to recover samples from the original data distribution by gradually removing noise. This can be described by the corresponding reverse SDE (Anderson, 1982 ) d â€‹ ğ’™ = [ âˆ’ Î² t 2 â€‹ ğ’™ âˆ’ Î² t â€‹ âˆ‡ ğ’™ t log â¡ p â€‹ ( ğ’™ t ) ] â€‹ d â€‹ t + Î² t â€‹ d â€‹ ğ’˜ Â¯ , d\bm{x}=[-\frac{\beta_{t}}{2}\bm{x}-\beta_{t}\nabla_{\bm{x}_{t}}\log p(\bm{x}_{t})]dt+\sqrt{\beta_{t}}d\bm{\bar{w}}, (3) where d â€‹ ğ’˜ Â¯ d\bm{\bar{w}} is the reverse-time Wiener process, and âˆ‡ ğ’™ t log â¡ p â€‹ ( ğ’™ t ) \nabla_{\bm{x}_{t}}\log p(\bm{x}_{t}) is the score function of the intermediate noisy distribution (Song Ermon, 2019 ; 2020 ) . A neural network is trained to approximate this score function, enabling sample generation by solving the reverse SDE. Latent Diffusion Models. We also consider Latent Diffusion Models (LDMs) (Rombach et al., 2022 ) , which perform the forward diffusion and reverse denoising processes in a lower-dimensional latent space instead of the pixel space. The original data ğ’™ \bm{x} is first mapped to a latent representation via an encoder â„° \mathcal{E} , resulting in ğ’› = â„° â€‹ ( ğ’™ ) \bm{z}=\mathcal{E}(\bm{x}) . The forward SDE is then applied in the latent space d â€‹ ğ’› = âˆ’ Î² t 2 â€‹ ğ’› + Î² t â€‹ d â€‹ ğ’˜ d\bm{z}=-\frac{\beta_{t}}{2}\bm{z}+\sqrt{\beta_{t}}d\bm{w} . After the reverse denoising process in the latent domain, a decoder ğ’Ÿ \mathcal{D} maps the denoised latent back to the data space. In our benchmark, we use a Vector Quantized Variational Autoencoder (VQ-VAE) (Van Den Oord et al., 2017 ) as the encoderâ€“decoder pair ( â„° , ğ’Ÿ ) (\mathcal{E},\mathcal{D}) following (Rombach et al., 2022 ; Rout et al., 2023 ; Song et al., 2024 ) . 3 DM4CT To apply diffusion models to inverse problems such as CT reconstruction, it is necessary to incorporate the measurement ğ’š \bm{y} into the reverse denoising process. From a Bayesian perspective, the posterior distribution over the unknown image given the measurements is expressed as p â€‹ ( ğ’™ | ğ’š ) âˆ p â€‹ ( ğ’™ ) â€‹ p â€‹ ( ğ’š | ğ’™ ) p(\bm{x}|\bm{y})\propto p(\bm{x})p(\bm{y}|\bm{x}) . This motivates a modification of the reverse-time SDE (Equation 3 ) to a conditional reverse SDE: d â€‹ ğ’™ = [ âˆ’ Î² t 2 â€‹ ğ’™ âˆ’ Î² t â€‹ ( âˆ‡ ğ’™ t log â¡ p â€‹ ( ğ’™ t ) + âˆ‡ ğ’™ t log â¡ p â€‹ ( ğ’š | ğ’™ t ) ) ] â€‹ d â€‹ t + Î² t â€‹ d â€‹ ğ’˜ Â¯ , d\bm{x}=\left[-\frac{\beta_{t}}{2}\bm{x}-\beta_{t}\left(\nabla_{\bm{x}_{t}}\log p(\bm{x}_{t})+\nabla_{\bm{x}_{t}}\log p(\bm{y}|\bm{x}_{t})\right)\right]dt+\sqrt{\beta_{t}}\,d\bar{\bm{w}}, (4) where âˆ‡ ğ’™ t log â¡ p â€‹ ( ğ’™ t ) \nabla_{\bm{x}_{t}}\log p(\bm{x}_{t}) is the score function approximated by the trained diffusion model, and âˆ‡ ğ’™ t log â¡ p â€‹ ( ğ’š | ğ’™ t ) \nabla_{\bm{x}_{t}}\log p(\bm{y}|\bm{x}_{t}) introduces a measurement-informed correction. However, this measurement term is generally intractable, since ğ’š \bm{y} typically depends on the clean image ğ’™ 0 \bm{x}_{0} rather than the noised version ğ’™ t \bm{x}_{t} . A common strategy is to approximate the conditional term using the clean image estimate ğ’™ ^ 0 â€‹ ( ğ’™ t ) \hat{\bm{x}}_{0}(\bm{x}_{t}) , âˆ‡ ğ’™ t log â¡ p â€‹ ( ğ’š | ğ’™ t ) â‰ˆ âˆ‡ ğ’™ t log â¡ p â€‹ ( ğ’š | ğ’™ ^ 0 â€‹ ( ğ’™ t ) ) . \nabla_{\bm{x}_{t}}\log p(\bm{y}|\bm{x}_{t})\approx\nabla_{\bm{x}_{t}}\log p(\bm{y}|\hat{\bm{x}}_{0}(\bm{x}_{t})). (5) There are two widely used estimators for ğ’™ ^ 0 â€‹ ( ğ’™ t ) \hat{\bm{x}}_{0}(\bm{x}_{t}) , both derived from the diffusion process. The first is based on the DDPM formulation (Ho et al., 2020 ) , ğ’™ ^ 0 = 1 Î± Â¯ â€‹ ( t ) â€‹ ( ğ’™ t âˆ’ 1 âˆ’ Î± Â¯ â€‹ ( t ) â€‹ âˆ‡ ğ’™ t log â¡ p â€‹ ( ğ’™ t ) ) \hat{\bm{x}}_{0}=\frac{1}{\sqrt{\bar{\alpha}(t)}}(\bm{x}_{t}-\sqrt{1-\bar{\alpha}(t)}\nabla_{\bm{x}_{t}}\log p(\bm{x}_{t})) . The second uses Tweedieâ€™s formula (Song et al., 2020 ; Kim Ye, 2021 ) , which directly relates the posterior mean to the score function: ğ’™ ^ 0 = 1 Î± Â¯ â€‹ ( t ) â€‹ ( ğ’™ t âˆ’ ( 1 âˆ’ Î± Â¯ â€‹ ( t ) ) â€‹ âˆ‡ ğ’™ t log â¡ p â€‹ ( ğ’™ t ) ) \hat{\bm{x}}_{0}=\frac{1}{\sqrt{\bar{\alpha}(t)}}\left(\bm{x}_{t}-(1-\bar{\alpha}(t))\nabla_{\bm{x}_{t}}\log p(\bm{x}_{t})\right) , where Î± Â¯ â€‹ ( t ) = âˆ j = 1 t ( 1 âˆ’ Î² j ) \bar{\alpha}(t)=\prod_{j=1}^{t}(1-\beta_{j}) is the cumulative noise schedule. These approximations enable conditioning on the measurement ğ’š \bm{y} during the reverse denoising process in a tractable way, forming the basis for a variety of measurement-aware diffusion reconstruction methods. 3.1 Diffusion Models for CT Reconstruction We compare nine representative diffusion-based methods for CT reconstruction. These methods differ primarily in how they incorporate the prior knowledge encoded by diffusion models into the inverse problem setting. Below, we briefly go through each strategy. Table 1: Diffusion-based methods evaluated in DM4CT. Columns under Technique refer to implementation choices (e.g., latent-space diffusion or DDIM-based sampling). Columns under Reconstruction Strategy denote how measurement conditioning is incorporated, including data consistency gradient steering (DC-grad), separate optimization steps (DC-step), plug-and-play priors, and use of approximate pseudoinverse solutions. A âœ“ âˆ— indicates only a single-step update toward the pseudoinverse. A âœ“ â€¡ indicates methods that incorporate data fidelity via a conjugate-gradient solve rather than