Title: MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models

Abstract: Molecular generation with diffusion models has emerged as a promising direction for AI-driven drug discovery and materials science. While graph diffusion models have been widely adopted due to the discrete nature of 2D molecular graphs, existing models suffer from low chemical validity and struggle to meet the desired properties compared to 1D modeling. In this work, we introduce MolHIT, a powerful molecular graph generation framework that overcomes long-standing performance limitations in existing methods. MolHIT is based on the Hierarchical Discrete Diffusion Model, which generalizes discrete diffusion to additional categories that encode chemical priors, and decoupled atom encoding that splits the atom types according to their chemical roles. Overall, MolHIT achieves new state-of-the-art performance on the MOSES dataset with near-perfect validity for the first time in graph diffusion, surpassing strong 1D baselines across multiple metrics. We further demonstrate strong performance in downstream tasks, including multi-property guided generation and scaffold extension.

Body: MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models 1 Introduction 2 Preliminaries 2.1 Discrete Diffusion Models Uniform transition Marginal transition Absorbing transition 2.2 Molecular Graph Generation with Discrete Diffusion 3 MolHIT Framework 3.1 Hierarchical Discrete Diffusion Models 3.2 Decoupled Atom Encoding 3.3 Forward and Reverse Process of MolHIT Forward process of MolHIT Grouping strategy Project and Noise (PN-sampler) Temperature sampling 3.4 Conditional Modeling 4 Experiments 4.1 Unconditional Generation on MOSES Evaluation Scaffold novelty metrics Baselines Result 4.2 Unconditional Generation on GuacaMol Setup Results 4.3 Multi-property guided generation Setup Evaluation Results 4.4 Scaffold Extension Setup Result 4.5 Ablation Studies Component analysis Effect of temperature sampling 5 Related Works Discrete diffusion models Diffusion models for molecular generation 6 Conclusion A Limitation and future directions Limitations Future directions B Further background B.1 Further related works Further backgrounds on discrete diffusion models Conditional generation with discrete diffusion B.2 Details of masked diffusion models Marginal transition C Mathematical derivations C.1 Generalized HDDM forward process Proof of Lemma 3.1 C.2 Proof of Theorem 3.2 Case 1. ğ³ t âˆˆ S 0 \mathbf{z}_{t}\in S_{0} Case 2. ğ³ t âˆˆ S 1 \mathbf{z}_{t}\in S_{1} Case 3. ğ³ t âˆˆ S 2 = { ğ¦ } \mathbf{z}_{t}\in S_{2}=\{\mathbf{m}\} Parameterization Case 1. ğ³ t âˆˆ S 0 \mathbf{z}_{t}\in S_{0} Case 2. ğ³ t âˆˆ S 1 \mathbf{z}_{t}\in S_{1} Case 3. ğ³ t âˆˆ S 2 = { ğ¦ } \mathbf{z}_{t}\in S_{2}=\{\mathbf{m}\} ELBO analysis Case 1. ğ³ t âˆˆ S 0 \mathbf{z}_{t}\in S_{0} Case 2. ğ³ t âˆˆ S 1 \mathbf{z}_{t}\in S_{1} Case 3. ğ³ t âˆˆ S 2 = { ğ¦ } \mathbf{z}_{t}\in S_{2}=\{\mathbf{m}\} D Experiment details D.1 Decoupled Atom Encoding (DAE) DAE in MOSES DAE in GuacaMol D.2 Grouping in HDDM Grouping Details for MOSES and GuacaMol D.3 Full experimental results with standard deviations D.4 Implementation of baselines D.5 Unconditional generation with MOSES and GuacaMol Training details Evaluation of MOSES Baselines D.6 Structure novelty metric D.7 Unconditional generation with GuacaMol GuacaMol experiment D.8 Multi-property guided generation Data construction Conditional graph transformer Evaluation details D.9 Scaffold extension Task Formulation Sampling Protocol Metric Definitions MolHIT: Advancing Molecular-Graph Generation with Hierarchical Discrete Diffusion Models Abstract Molecular generation with diffusion models has emerged as a promising direction for AI-driven drug discovery and materials science. While graph diffusion models have been widely adopted due to the discrete nature of 2D molecular graphs, existing models suffer from low chemical validity and struggle to meet the desired properties compared to 1D modeling. In this work, we introduce MolHIT , a powerful molecular graph generation framework that overcomes long-standing performance limitations in existing methods. MolHIT is based on the Hierarchical Discrete Diffusion Model, which generalizes discrete diffusion to additional categories that encode chemical priors, and decoupled atom encoding that splits the atom types according to their chemical roles. Overall, MolHIT achieves new state-of-the-art performance on the MOSES dataset with near-perfect validity for the first time in graph diffusion, surpassing strong 1D baselines across multiple metrics. We further demonstrate strong performance in downstream tasks, including multi-property guided generation and scaffold extension. \icml@noticeprintedtrue Hojung Jung 1,âˆ— , Rodrigo Hormazabal 2 , Jaehyeong Jo 1 , Youngrok Park 1 , Kyunggeun Roh 3 , Se-Young Yun 1 , Sehui Han 2 , Dae-Woong Jeong 2 1 KAIST AI 2 LG AI Research 3 Seoul National University ghwjd7281@kaist.ac.kr {NoHyper} 0 0 footnotetext: âˆ— Work done during an internship at LG AI Research. 1 Introduction Figure 1 : MolHIT achieves SOTA result on MOSES dataset. (Top) Near-perfect validity, outperforming existing graph diffusion models. (Bottom) Pareto-optimal in quality-novelty trade-off. Figure 2 : Overview of MolHIT . (a) Markov chain of Hierarchical Discrete Diffusion Model (HDDM). Clean states ( S 0 S_{0} ) are transited to the mid-level states ( S 1 S_{1} ) and finally to the masked state ( S 2 S_{2} ). (b) Generation process of MolHIT. From the masked prior, atoms are denoised into mid-level states and then to atomic tokens in a coarse-to-fine manner. (c) Phase diagram of HDDM showing the transition probability of the forward process. (d) Decoupled atom encoding scheme, separately encoding the aromatic and charged atom types. Molecular generation with AI has the potential to significantly speed up materials design (Sanchez-Lengeling and Aspuru-Guzik, 2018 ) and drug discovery (Zhang et al., 2025 ) . While this promise has led to many different modeling strategies, generating valid and novel molecules is challenging due to the vast combinatorial search space (Dobson, 2004 ) . Here, the primary challenge is not generating novel structures, but ensuring the structures remain chemically valid and relevant. Even a minor atom-level error can produce a structure that is chemically impossible or synthetically inaccessible. Consequently, it is necessary to develop generative models that efficiently explore this immense chemical space while generating valid and synthesizable molecules. One common approach is to treat molecules as 1D sequences, most commonly through the SMILES representation (Weininger, 1988 ) . By representing molecular graphs into strings, these models can leverage powerful natural language processing techniques to learn patterns of characters. While this simpler learning objective results in generating valid molecules, they suffer from memorization, often reproducing patterns or common subsequences in the training set. This limited exploration capability creates a performance plateau as shown in Fig. 1 , where high validity is achieved at the expense of a reduced number of new structures. To overcome the exploration limits of sequence-based approaches, graph generative models (Jo et al., 2022 ; Liu et al., 2023 ) treat molecules as interconnected systems of atoms and bonds. Unlike 1D models that often overfit to specific textual patterns, graph-based architectures are designed to internalize the underlying topological principles of chemical structures, allowing them to generalize beyond the training set and discover novel structures. In particular, discrete diffusion models (Austin et al., 2021 ) have been widely studied for molecular graph generation as they naturally align with the categorical nature of atoms and bonds (Vignac et al., 2022 ; Xu et al., 2024 ; Qin et al., 2024 ; Seo et al., 2025 ) . While these models excel at structural exploration, they are prone to generating invalid or chemically unstable samples compared to well-optimized 1D models. This creates a performance gap that raises a fundamental research question: Can we leverage the inductive biases of graph modeling to match the validity of sequence models while maintaining their superior capacity for structural novelty? We identify two critical limitations in existing molecular graph generation with discrete diffusion. (1) First, current uniform or absorbing transition treats each atom category as an independent category, even though there is well known chemical relationship that some atoms are easier to be replaced with another. Neglecting well-established domain priors often makes the learning unnecessarily hard, especially in molecular settings where high-quality molecule data is scarce. (2) Second, existing graph models rely on naive atom encodings, ignoring the fact that a single atom can have different characteristics when it has a formal charge or consists of a ring (aromaticity). We reveal that this makes molecular graph generation tasks ill-posed and unnecessarily challenging, which we demonstrate in the reconstruction experiments in Fig. 3 where previous atom encoding fails. In light of these observations, we introduce MolHIT, a hierarchical discrete diffusion framework designed to bridge the gap between structural innovation and chemical validity. Our framework is built upon the Hierarchical Discrete Diffusion Model (HDDM), where additional categories are added to represent natural chemical groups into the diffusion process. This coarse-to-fine approach allows the model to establish high-level chemical identities before refining them into specific atom types, thereby capturing the meaningful dependencies of molecular structure that uniform or absorbing kernels often overlook. Furthermore, we introduce Decoupled Atom Encoding (DAE) to resolve the information loss found in naive representations by explicitly split atoms based on their specific chemical roles, such as formal charge and aromaticity. By providing a chemical role into each token, DAE not only resolves the reconstruction problem in original atom encoding, but also reduces the burden of differentiating atom roles solely with the ( O â€‹ ( n 2 ) O(n^{2}) ) bond features. Combined together, MolHIT reaches a new Pareto frontier in generating novel structures with high quality, surpassing both existing 1D and 2D models (Fig. 1 ). We extensively evaluate MolHIT with experiments on large molecular benchmarks, including unconditional generation tasks on MOSES (Polykovskiy et al., 2020 ) and GuacaMol (Brown et al., 2019 ) benchmarks and conditional generation tasks, including scaffold extension and multi-property guided generation tasks. Across all benchmarks and tasks, MolHIT shows significant improvements over previous graph diffusion models, resulting in a new state-of-the-art that surpass 1D models. Our contributions can be summarized as follows: â€¢ We introduce MolHIT , a molecular graph diffusion model built upon a novel Hierarchical Discrete Diffusion Model (HDDM) framework with a mathematically guaranteed ELBO. â€¢ We identify a critical limitation in the prior graph generative modelsâ€™ atom encoding and propose a simple solution: Decoupled Atom Encoding (DAE) . By representing atoms based on their specific chemical roles, we find DAE enhances both the modelâ€™s generative expressiveness and chemical reliability. â€¢ We achieve the SOTA performance on the MOSES benchmarks in multiple metrics, significantly outperforming both existing graph diffusion models and 1D sequence-level baselines. â€¢ We test our algorithm on practical downstream tasks including multi-property guided generation and scaffold extension, achieving the highest performance compared to the previous graph diffusion approach. 2 Preliminaries Figure 3 : Existing atom encoding for molecular graph is ill-posed. (Left) Reconstruction success rate on the Moses dataset with previous encoding and our decoupled atom encoding. (Right) Proportion of generated molecules containing pyrrolic nitrogen [ n â€‹ H ] [nH] . 2.1 Discrete Diffusion Models Given a discrete state space S S with K K categories, discrete diffusion models define a noising and denoising process within a discrete space. Specifically, for ğ± âˆˆ S \mathbf{x}\in S , the noising process is described by a Markov chain as follows: q â€‹ ( ğ± t | ğ± t âˆ’ 1 ) = Cat â€‹ ( ğ± t ; ğ± t âˆ’ 1 â€‹ Q t ) . q(\mathbf{x}_{t}|\mathbf{x}_{t-1})=\mathrm{Cat}(\mathbf{x}_{t};\mathbf{x}_{t-1}Q_{t}). (1) Here, marginal probability of ğ± t \mathbf{x}_{t} in timestep t t , given clean data ğ± 0 \mathbf{x}_{0} can be calculated with q â€‹ ( ğ± t | ğ± 0 ) = Cat â€‹ ( ğ± t ; ğ± 0 â€‹ Q Â¯ t ) , Q Â¯ t = Q t â€‹ Q t âˆ’ 1 â€‹ â‹¯ â€‹ Q 1 . q(\mathbf{x}_{t}|\mathbf{x}_{0})=\mathrm{Cat}(\mathbf{x}_{t};\mathbf{x}_{0}\bar{Q}_{t}),\;\;\bar{Q}_{t}=Q_{t}Q_{t-1}\cdots Q_{1}. (2) As shown by Austin et al. ( 2021 ) , one can design multiple types of diffusion process, where two types of processes are widely used because of the closed-form calculation of the forward process and natural noising process. Uniform transition Uniform transition assumes uniform prior p T â€‹ ( ğ± T = c ) = 1 K p_{T}(\mathbf{x}_{T}=c)=\frac{1}{K} for all â€‹ c âˆˆ { 1 , â€¦ , K } \text{for all }c\in\{1,\dots,K\} . Then one could define a forward noising process by interpolating clean data ğ± 0 \mathbf{x}_{0} with the prior in the following way: q â€‹ ( ğ± t | ğ± 0 ) = Cat â€‹ ( ğ± t ; ( 1 âˆ’ Î± Â¯ t ) â€‹ 1 K â€‹ ğŸğŸ T + Î± Â¯ t â€‹ ğ± 0 ) , q(\mathbf{x}_{t}|\mathbf{x}_{0})=\mathrm{Cat}(\mathbf{x}_{t};(1-\bar{\alpha}_{t})\frac{1}{K}\mathbf{1}\mathbf{1}^{T}+\bar{\alpha}_{t}\mathbf{x}_{0}), (3) where Î± Â¯ t \bar{\alpha}_{t} is monotonic decreasing function with Î± Â¯ 0 ] = 1 , Î± Â¯ T = 0 \bar{\alpha}_{0}]=1,\bar{\alpha}_{T}=0 , which we call diffusion scheduler. Marginal transition To facilitate the diffusion learning, marginal transition assumes data prior Ï€ \pi to be an optimal probability distribution that approximates the empirical data distribution from the training set. This has been primarily adopted for graph diffusion models DiGress (Vignac et al., 2022 ; Siraudin et al., 2024 ) , where further details are in Appendix B.2 . Absorbing transition Unlike uniform and marginal transition where diffusion process operates on the given K categories, one can introduce an additional masked (absorbing) state ğ¦ \mathbf{m} with prior ğ ğ¦ \mathbf{e_{m}} being a one-hot vector of the masked state. Then, one can naturally define a diffusion process as an absorbing process in a Markov chain, which results in the following forward form: q â€‹ ( ğ± t | ğ± 0 ) = Cat â€‹ ( ğ± t ; Î± Â¯ t â€‹ ğ± 0 + ( 1 âˆ’ Î± Â¯ t ) â€‹ ğ ğ¦ ) . q(\mathbf{x}_{t}|\mathbf{x}_{0})=\mathrm{Cat}(\mathbf{x}_{t};\bar{\alpha}_{t}\mathbf{x}_{0}+(1-\bar{\alpha}_{t})\mathbf{e_{m}}). (4) Given q â€‹ ( ğ± t âˆ’ 1 | ğ± t , ğ± 0 ) = Cat â€‹ ( ğ± t âˆ’ 1 ; ğ± t â€‹ Q t | s âŠ¤ âŠ™ ğ± 0 â€‹ Q Â¯ t âˆ’ 1 ğ± 0 â€‹ Q Â¯ t â€‹ ğ± t T ) q(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0})=\mathrm{Cat}(\mathbf{x}_{t-1};\frac{\mathbf{x}_{t}Q_{t|s}^{\top}\;\odot\;\mathbf{x}_{0}\bar{Q}_{t-1}}{\mathbf{x}_{0}\bar{Q}_{t}\mathbf{x}_{t}^{T}}) , one could estimate posterior p Î¸ â€‹ ( ğ± t âˆ’ 1 | ğ± t , ğ± 0 ) p_{\theta}(\mathbf{x}_{t-1}|\mathbf{x}_{t},\mathbf{x}_{0}) by learning to estimate the clean data ğ± ^ 0 \hat{\mathbf{x}}_{0} given the noisy data ğ± t \mathbf{x}_{t} . This enables training the diffusion models with simple cross-entropy loss, where the loss function becomes directly linked to the negative evidence lower bound (NELBO) (Austin et al., 2021 ; Sahoo et al., 2024 ) . 2.2 Molecular Graph Generation with Discrete Diffusion Given molecular graph G = ( X , E ) G=(X,E) , denote X âˆˆ â„ n Ã— d X X\in\mathbb{R}^{n\times d_{X}} , E âˆˆ â„ n Ã— n Ã— d E E\in\mathbb{R}^{n\times n\times d_{E}} for the atom matrix and adjacency matrix (bond matrix) where n n is the number of atoms and d X , d E d_{X},d_{E} are feature dimensions of atoms and edges. The forward process of discrete diffusion operates independently on the atom and bond matrices: G t = ( ğ— t , ğ„ t ) : ğ— t = ğ— 0 â€‹ ğ Â¯ ğ— , t , ğ„ t = ğ„ 0 â€‹ ğ Â¯ ğ„ , t . \displaystyle G_{t}=(\mathbf{X}_{t},\mathbf{E}