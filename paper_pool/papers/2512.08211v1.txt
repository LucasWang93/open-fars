Title: MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones

Abstract: Mobile phones are the most ubiquitous end devices, generating vast amounts of human-authored data and serving as the primary platform for end-side applications. As high-quality public data for large language models (LLMs) approaches exhaustion, on-device fine-tuning provides an opportunity to leverage private user data while preserving privacy. However, existing approaches are predominantly simulation-based or rely on IoT devices and PCs, leaving commodity mobile phones largely unexplored. A key gap is the absence of an open-source framework that enables practical LLM fine-tuning on mobile phones. We present MobileFineTuner, a unified open-source framework that enables end-to-end LLM fine-tuning directly on commodity mobile phones. MobileFineTuner is designed for efficiency, scalability, and usability, supporting full-parameters fine-tuning (Full-FT) and parameter-efficient fine-tuning (PEFT). To address the memory and energy limitations inherent to mobile phones, we introduce system-level optimizations including parameter sharding, gradient accumulation, and energy-aware computation scheduling. We demonstrate the practicality of MobileFineTuner by fine-tuning GPT-2, Gemma 3, and Qwen 2.5 on real mobile phones. Extensive experiments and ablation studies validate the effectiveness of the proposed optimizations and establish MobileFineTuner as a viable foundation for future research on on-device LLM training.

Body: MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones 1 Introduction 2 Related Work 2.1 Leveraging Private-Domain Data for on-device LLM Fine-Tuning 2.2 Limitations of Existing Efforts on LLM Fine-Tuning on Mobile Phones 3 MobilFineTuner Framework 3.1 Framemwork Details and APIs 3.2 Usage Process for Full-FT and PEFT 3.3 Comparison with Mature Frameworks for LLM Implementation 4 Built-in Optimizations 4.1 Memory Optimization 4.1.1 ZeRO-inspired parameters sharding 4.1.2 Gradients accumulation. 4.2 Energy Optimization 5 Implementation 5.1 Device Setup 5.1.1 Framework compilation 5.1.2 Metrics observer 5.1.3 Device specifications for our common evaluation. 5.1.4 Device specifications for our common evaluation. 5.2 Models 5.3 Datasets 6 Framework Evaluation 6.1 Base Evaluation 6.1.1 Full-FT 6.1.2 PEFT(LoRA) 6.2 Evaluation of Built-in Optimizations 6.2.1 Parameters Sharding 6.2.2 Gradients Accumulation 6.2.3 Computation Scheduling 7 Conclusion MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones *Jiaxiang Geng 1,2 *Lunyu Zhao 1 *Yiyi Lu 1 Bing Luo 1 1 Duke Kunshan University, Kunshan, China 2 The University of Hong Kong, Hong Kong, China jg645,lz269,yl996,bl291@duke.edu Abstract. Mobile phones are the most ubiquitous end devices, generating vast amounts of human-authored data and serving as the primary platform for end-side applications. As high-quality public data for large language models (LLMs) approaches exhaustion, on-device fine-tuning provides an opportunity to leverage private user data while preserving privacy. However, existing approaches are predominantly simulation-based or rely on IoT devices and PCs, leaving commodity mobile phones largely unexplored. A key gap is the absence of an open-source framework that enables practical LLM fine-tuning on mobile phones. We present MobileFineTuner, a unified open-source framework that enables end-to-end LLM fine-tuning directly on commodity mobile phones. MobileFineTuner is designed for efficiency, scalability, and usability, supporting full-parameters fine-tuning (Full-FT) and parameter-efficient fine-tuning (PEFT). To address the memory and energy limitations inherent to mobile phones, we introduce system-level optimizations including parameter sharding, gradient accumulation, and energy-aware computation scheduling. We demonstrate the practicality of MobileFineTuner by fine-tuning GPT-2, Gemma 3, and Qwen 2.5 on real mobile phones. Extensive experiments and ablation studies validate the effectiveness of the proposed optimizations and establish MobileFineTuner as a viable foundation for future research on on-device LLM training. Fine-tuning, Mobile phones, Large language models * These authors contribute equally to this work. Corresponding Author: Bing Luo. † † conference: MobileFineTuner: A Unified End-to-End Framework for Fine-Tuning LLMs on Mobile Phones; June 21–25, 2026; Cambridge, UK † † ccs: Computing methodologies Distributed artificial intelligence 1. Introduction Large language models (LLMs), such as GPT (OpenAI et al., 2024 ) , LLama (Touvron et al., 2023 ) and Gemma (GemmaTeam et al., 2025 ) , have achieved remarkable success by training on massive public datasets. Nevertheless, recent analyses suggest a growing concern that the supply of high-quality human-generated public data may be exhausted between 2026 and 2032 (Villalobos et al., 2024 ) . Early signs of this scarcity are already apparent: rather than actively collecting or generating new data, an increasing number of studies rely on repackaging existing datasets (Wang et al., 2023a ) or on synthetic corpora generated by LLMs themselves (Wang et al., 2023b ) . This trend highlights a looming bottleneck for LLM development, as scaling laws indicate that model performance continues to improve with access to larger and higher-quality training data (Kaplan et al., 2020 ) , which synthetic data may not fully replace. Meanwhile, enormous amounts of valuable private-domain data reside on end devices, especially on the billions of mobile phones that people use in daily life (Almeida et al., 2021 ) . This data - such as personal communication logs, notes, and app interactions - is highly relevant for personalization and downstream adaptation of LLMs (Li et al., 2024 ) . However, transmitting such sensitive data directly to a central server for fine-tuning raises severe privacy concerns (Gunter et al., 2024 ) . Such practices may conflict with data protection regulations such as the General Data Protection Regulation (GDPR) (European Parliament and Council of the European Union, 2016 ) and often contradict user expectations, particularly in domains such as finance (Wu et al., 2023 ) and healthcare (Thirunavukarasu et al., 2023 ) . To leverage private data while preserving privacy, recent work has explored on-device federated LLM fine-tuning (Li et al., 2025 ; Zhang et al., 2024 ) and personalized LLM fine-tuning (Wagner et al., 2024 ; Qin et al., 2024 ) . These approaches ensure that data remains on end devices during training (Fan et al., 2025a ) . However, existing implementations are mostly simulation-based, or they run on Internet-of-Things (IoT) devices such as NVIDIA developer boards, or on personal computers (PCs). In contrast, commodity mobile phones, which generate vast amounts of human-authored data, are rarely used as practical platforms for LLM fine-tuning. From a systems perspective, the main obstacle to enabling LLM fine-tuning on mobile phones is the lack of a framework that supports flexible and scalable training in mobile environments. Popular LLM fine-tuning frameworks—such as PyTorch or Hugging Face Transformers—rely heavily on Python and native Linux/Windows runtimes (Paszke et al., 2019 ; Wolf et al., 2019 ) , making them incompatible with mobile operating systems. Moreover, Mobile phones, in contrast, do not natively support Python (Python Software Foundation, 2025 ) , which prevents these mature LLM fine-tuning frameworks from being used on mobile devices, creating a critical gap in the infrastructure necessary for on-device LLM fine-tuning. To bridge this gap, we present MobileFineTuner , a unified open-source framework that enables practical LLM fine-tuning directly on commodity mobile phones. MobileFineTuner provides an end-to-end system that supports experimentation with both algorithmic innovations and systems-level challenges in on-device LLM training. MobilefineTuner is designed around three key properties: efficiency , scalability , and usability . Efficiency. MobileFineTuner is developed entirely in C++ with a modular operator design that implements automatic differentiation and full backpropagation natively on mobile hardware. By avoiding Python runtimes, virtual machines (VM), and external ML frameworks, the system achieves substantially lower runtime and memory overhead, enabling practical LLM fine-tuning under the tight resource constraints of mobile phones. Scalability. MobileFineTuner supports multiple mainstream LLM architectures and can be easily extended to new models or downstream tasks through its modular operator interface. The system enables both full-parameter fine-tuning (Full-FT) and parameter-efficient fine-tuning (PEFT, e.g., LoRA), and provides flexible interfaces for integrating custom training strategies such as federated fine-tuning. This design makes the framework scalable across model families, training algorithms, and deployment settings. Usability. MobilefineTuner is distributed as a standalone package with simple high-level APIs that abstract away low-level operator management and system complexity. This design allows both researchers and developers to fine-tune LLMs on mobile phones with minimal integration effort, facilitating rapid prototyping and practical mobile AI application development. While these properties make MobileFineTuner broadly applicable, enabling LLM fine-tuning on mobile devices requires addressing two fundamental hardware constraints: limited memory capacity and strict energy budgets . These constraints shape both the feasibility and performance of on-device training and therefore motivate several system-level optimizations in MobileFineTuner. Memory optimization. MobileFineTuner combines two complementary techniques to reduce peak RAM usage. First, it uses a ZeRO-inspired parameter sharding mechanism that offloads inactive parameters to disk. Second, it adopts gradient accumulation to divide large batches into micro-batches, enabling stable forward and backward computation under tight memory budgets. Energy optimization. To handle mobile energy constraints, MobileFineTuner includes an energy-aware computation scheduler that adjusts computation frequency according to battery level, reducing power draw during sustained fine-tuning. In summary, MobileFineTuner fills a critical gap in the current on-device LLM ecosystem by enabling practical, privacy-preserving, and resource-aware fine-tuning directly on commodity mobile devices. Our contributions are as follows: • A unified framework for LLM fine-tuning on mobile phones. We develop MobileFineTuner, an open-source framework that enables practical end-to-end Full-FT and PEFT of mainstream LLMs on commodity mobile phones. We opensourse our framework at: https://github.com/AndyLu666/MobileFineTuner . • System-level techniques for overcoming mobile memory and energy constraints. We design and integrate optimizations-including ZeRO-inspired parametern sharding, gradient accumulation, and an energy-aware computation scheduler-that make LLM fine-tuning feasible on mobile hardware. • A comprehensive empirical study across models, devices and data tasks. We validate MobilefineTuner through extensive experiments and ablations, demonstrating its effectiveness and performing ablations to quantify the impact of the proposed memory and energy optimizations. Roadmap: The roadmap of this paper is shown in Fig. 1 . In Section 2, we discuss the background and related works. In Section 3, we introduce MobileFineTuner, including its framework and APIs, the processes for using Full-FT and PEFT, and a comparison between MobileFineTuner and existing mature LLM implementation frameworks. In Section 4, we present the built-in optimizations, including memory optimization and energy optimization. Sections 5 and 6 present experimental validation. Figure 1. MobileFineTuner overview. 2. Related Work In this section, we review prior work related to LLM fine-tuning from two perspectives. First, we discuss methods that leverage private-domain data for on-device LLM fine-tuning, examine the implementation setups they rely on, and analyze why they do not typically adopt mobile phones as target platforms. Second, we review recent efforts that attempt to enable LLM fine-tuning on mobile phones, analyzing their implementation strategies and inherent limitations. 2.1. Leveraging Private-Domain Data for on-device LLM Fine-Tuning To leverage private-domain data for LLM fine-tuning, recent works have proposed several approaches that allow data on end devices to participate in the fine-tuning process while preserving privacy by ensuring the data never leaves the device. These methods can be broadly categorized into two groups. The first is on-device federated LLM fine-tuning, where models trained on multiple clients are aggregated by a federated server to obtain a globally fine-tuned model. The second is on-device personalized LLM fine-tuning, which focuses on adapting LLMs to achieve better personalization on a specific end device. For on-device federated LLM fine-tuning, methods such as FedIT (Zhang et al., 2024 ) , FLoRA (Wang et al., 2024 ) , HeLoRA (Fan et al., 2025b ) , HetLoRA (Cho et al., 2024 ) , and PCFT-LLM (Wagner et al., 2024 ) investigate federated LoRA-based techniques to enable PEFT of LLMs across heterogeneous client devices. Similarly, ME-SFL (Chen et al., 2025 ) and FlexP-SFL (Yuan et al., 2025 ) explore split learning-based solutions for federated LLM fine-tuning across distributed and heterogeneous edge systems. Table 1. Recent methods on leveraging private-domain data for LLM fine-tuning. Method On-device Fine-tuning Target Based Framework Implementation Setup Open Source FedIT (Zhang et al., 2024 ) √ \surd Transformers and Huggingface PEFT Simulation √ \surd FLoRA (Wang et al., 2024 ) √ \surd PyTorch and Transformers Simulation √ \surd HeLoRA (Fan et al., 2025b ) √ \surd PyTorch and Flower Simulation √ \surd HetLoRA (Cho et al., 2024 ) √ \surd Not mentioned Simulation × \times PCFT-LLM (Wagner et al., 2024 ) √ \surd PyTorch and Transformers Simulation √ \surd ME-SFL (Chen et al., 2025 ) √ \surd Not mentioned NVIDIA developer boards, SoCs and PCs × \times FlexP-SFL (Yuan et al., 2025 ) √ \surd PyTorch NVIDIA developer boards and RasberryPi √ \surd MobiLLM (Li et al., 2025 ) √ \surd PyTorch and Transformers NVIDIA developer boards and PCs × \times PAE-MobiLLM (Yang et al., 2025 ) √ \surd PyTorch and Transformers NVIDIA developer boards and PCs × \times PocketLLM (Peng et al., 2024 ) √ \surd PyTorch and Transformers by Termux (inefficiency due to the VM) Mobile Phones × \times XPerT (Wang et al., 2025 ) √ \surd ONNX Runtime Python API (high-cost offline development) Mobile Phones × \times SP-LLM (Qin et al., 2024 ) √ \surd Not mentioned Simulation × \times Crayon (Bang et al., 2024 ) √ \surd PyTorch and Huggingface PEFT Simulation × \times For on-device personalized LLM fine-tuning, methods such as MobiLLM (Li et al., 2025 ) and PAE-MobiLLM (Yang et al., 2025 ) adopt side-tuning strategies, where server-side resources assist mobile or edge devices in adapting LLMs to local data distributions. PocketLLM (Peng et al., 2024 ) proposes a memory-efficient fine-tuning technique that relies only on forward propagation to significantly reduce device memory usage. XPerT (Wang et al., 2025 ) studies personalized LLM selection to better adapt models for different devices. SP-LLM (Qin et al., 2024 ) focuses on selecting the most representative local data samples for efficient on-device fine-tuning. Crayon (Bang et al., 2024 ) introduces an adapter-pool mechanism that enables effective personalization with minimal additional computing overhead. We summarize these works in Tab. 1 , highlighting the frameworks, implementation setups, and open-source availability. The comparison reveals a notable gap: although all of these methods aim at enabling on-device LLM fine-tuning, among the 13 surveyed works, 7 works (over half) rely on simulation-based experiments, 4 works employ NVIDIA developer boards, SoCs, Raspberry Pis or PCs, while only 2 works (PocketLLM and XPerT) actually evaluate their methods on mobile phones. This raises a critical question: given that mobile phones are the most ubiquitous end devices in daily life, generating massive amounts of human-generated data and serving as the primary target platform for most end-side applications, why ar